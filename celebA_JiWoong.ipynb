{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 정의 아아아"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, stride):\n",
    "    super(Block, self).__init__()\n",
    "    self.conv = nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 4, stride, 1, bias = True, padding_mode = 'reflect'),\n",
    "        nn.InstanceNorm2d(out_channels),\n",
    "        nn.LeakyReLU(0.2)\n",
    "    )\n",
    "  def forward(self, x):\n",
    "    return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "  def __init__(self, in_channels = 3, features = [64, 128, 256, 512]):\n",
    "    super(Discriminator, self).__init__()\n",
    "    self.initial = nn.Sequential(\n",
    "        nn.Conv2d(in_channels, features[0], kernel_size = 4, stride = 2, padding = 1, padding_mode ='reflect'), # Conv(3, 64, 4, 2, 1)\n",
    "    nn.LeakyReLU(0.2))\n",
    "\n",
    "    layers = []\n",
    "    in_channels = features[0]\n",
    "    for feature in features[1:]:\n",
    "      layers.append(Block(in_channels, feature, stride = 1 if feature == features[-1] else 2)) #Conv(64,128, 4, 2, 1),Conv(128,256, 4, 2, 1), Conv(256, 512, 4, 1, 1)  담는다\n",
    "      in_channels = feature # \n",
    "    layers.append(nn.Conv2d(in_channels,1, kernel_size = 4, stride = 1, padding = 1, padding_mode = 'reflect')) #Conv(512, 1, 4, 1, 1)\n",
    "    self.model = nn.Sequential(*layers)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.initial(x)\n",
    "    return torch.sigmoid(self.model(x)) # 30 x 30 pathgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 30, 30])\n",
      "tensor([[0.4631, 0.5908, 0.4057, 0.4463, 0.6417, 0.4821, 0.4718, 0.6237, 0.5126,\n",
      "         0.4072, 0.6165, 0.5786, 0.6251, 0.5631, 0.6481, 0.5670, 0.6897, 0.5566,\n",
      "         0.4536, 0.5710, 0.4960, 0.3451, 0.6395, 0.5704, 0.4811, 0.4518, 0.6004,\n",
      "         0.3048, 0.2735, 0.5724],\n",
      "        [0.3112, 0.3363, 0.3049, 0.4522, 0.4794, 0.4035, 0.4608, 0.5535, 0.5830,\n",
      "         0.4789, 0.5619, 0.4953, 0.4221, 0.4789, 0.4908, 0.4541, 0.6596, 0.5759,\n",
      "         0.4776, 0.4037, 0.6254, 0.4026, 0.6461, 0.6150, 0.5473, 0.3298, 0.5606,\n",
      "         0.3883, 0.4847, 0.5804],\n",
      "        [0.5445, 0.6643, 0.3747, 0.3694, 0.4362, 0.4018, 0.5196, 0.6490, 0.5155,\n",
      "         0.4531, 0.5204, 0.6869, 0.4934, 0.6227, 0.7982, 0.4828, 0.7001, 0.6651,\n",
      "         0.5130, 0.3974, 0.3949, 0.3718, 0.4581, 0.4544, 0.6575, 0.5570, 0.4910,\n",
      "         0.5446, 0.4154, 0.6316],\n",
      "        [0.4439, 0.6489, 0.3646, 0.6612, 0.5526, 0.4653, 0.4686, 0.6198, 0.6376,\n",
      "         0.6451, 0.5261, 0.4160, 0.5521, 0.6197, 0.5016, 0.5288, 0.5108, 0.2957,\n",
      "         0.4125, 0.6005, 0.3444, 0.4418, 0.4458, 0.4105, 0.4077, 0.3235, 0.3886,\n",
      "         0.4860, 0.4108, 0.5336],\n",
      "        [0.7310, 0.6460, 0.5609, 0.4189, 0.6556, 0.5524, 0.4750, 0.4676, 0.3797,\n",
      "         0.5630, 0.4996, 0.3921, 0.4531, 0.4938, 0.3241, 0.5536, 0.5971, 0.4048,\n",
      "         0.4650, 0.5539, 0.5034, 0.5259, 0.3990, 0.3656, 0.4320, 0.4362, 0.5262,\n",
      "         0.3113, 0.4982, 0.4556],\n",
      "        [0.4970, 0.5323, 0.5889, 0.6326, 0.5979, 0.7165, 0.5988, 0.3303, 0.5319,\n",
      "         0.5086, 0.3611, 0.5234, 0.3909, 0.3770, 0.3410, 0.4087, 0.6139, 0.4591,\n",
      "         0.4817, 0.4158, 0.4476, 0.5880, 0.5808, 0.5272, 0.3599, 0.5393, 0.7125,\n",
      "         0.4446, 0.4942, 0.4521],\n",
      "        [0.4756, 0.5529, 0.4310, 0.3687, 0.4610, 0.4362, 0.5190, 0.5040, 0.4634,\n",
      "         0.5303, 0.5265, 0.5656, 0.4883, 0.4236, 0.5130, 0.5059, 0.5268, 0.4631,\n",
      "         0.6538, 0.6453, 0.4160, 0.6293, 0.5466, 0.6170, 0.4357, 0.3724, 0.4688,\n",
      "         0.5840, 0.6040, 0.6574],\n",
      "        [0.4164, 0.5937, 0.3544, 0.3103, 0.6414, 0.4972, 0.6508, 0.4109, 0.3681,\n",
      "         0.6154, 0.5196, 0.4364, 0.3760, 0.6200, 0.4449, 0.6052, 0.4780, 0.3662,\n",
      "         0.6229, 0.3871, 0.6663, 0.5283, 0.6103, 0.4216, 0.4577, 0.4646, 0.5918,\n",
      "         0.4191, 0.4802, 0.4937],\n",
      "        [0.5672, 0.4588, 0.5359, 0.5641, 0.3194, 0.5830, 0.4249, 0.4306, 0.5375,\n",
      "         0.6349, 0.6119, 0.4090, 0.4965, 0.3719, 0.5492, 0.5895, 0.3648, 0.5023,\n",
      "         0.4705, 0.5750, 0.4500, 0.4415, 0.5139, 0.5006, 0.4152, 0.4008, 0.6568,\n",
      "         0.5270, 0.5870, 0.5569],\n",
      "        [0.5848, 0.5905, 0.4515, 0.4885, 0.5329, 0.5259, 0.5054, 0.5257, 0.6114,\n",
      "         0.5995, 0.3646, 0.5186, 0.5649, 0.5551, 0.5321, 0.5794, 0.3483, 0.3717,\n",
      "         0.5706, 0.5165, 0.4943, 0.5018, 0.3695, 0.6139, 0.5118, 0.5484, 0.5208,\n",
      "         0.4788, 0.6104, 0.5380],\n",
      "        [0.6034, 0.5694, 0.4907, 0.8059, 0.3229, 0.6045, 0.3445, 0.5178, 0.5018,\n",
      "         0.4357, 0.5543, 0.5319, 0.5088, 0.5121, 0.4550, 0.6351, 0.5924, 0.4822,\n",
      "         0.4819, 0.6490, 0.6035, 0.6209, 0.4069, 0.5100, 0.4132, 0.5450, 0.4326,\n",
      "         0.6080, 0.5642, 0.5088],\n",
      "        [0.5314, 0.5026, 0.6233, 0.5279, 0.6827, 0.3434, 0.4833, 0.5171, 0.5485,\n",
      "         0.5113, 0.5318, 0.5474, 0.5893, 0.4777, 0.4541, 0.4108, 0.7396, 0.6357,\n",
      "         0.6564, 0.3963, 0.4246, 0.5690, 0.3871, 0.6120, 0.5456, 0.4633, 0.5987,\n",
      "         0.5786, 0.5399, 0.3826],\n",
      "        [0.3577, 0.3596, 0.4810, 0.5358, 0.2874, 0.3664, 0.3789, 0.6641, 0.4602,\n",
      "         0.4649, 0.5559, 0.5586, 0.4575, 0.6386, 0.5378, 0.4486, 0.4724, 0.5645,\n",
      "         0.6164, 0.5186, 0.5620, 0.5952, 0.5697, 0.5270, 0.5453, 0.4398, 0.4155,\n",
      "         0.6000, 0.5604, 0.6284],\n",
      "        [0.4946, 0.4481, 0.5643, 0.4323, 0.5620, 0.4564, 0.4266, 0.4624, 0.5846,\n",
      "         0.2824, 0.6327, 0.5804, 0.6418, 0.5700, 0.6580, 0.4491, 0.3176, 0.5415,\n",
      "         0.5017, 0.6152, 0.4295, 0.6945, 0.5257, 0.5801, 0.5041, 0.6250, 0.3047,\n",
      "         0.4061, 0.5148, 0.4675],\n",
      "        [0.4360, 0.6226, 0.5861, 0.5233, 0.5494, 0.4156, 0.4490, 0.5324, 0.4297,\n",
      "         0.6265, 0.4809, 0.4768, 0.4733, 0.4408, 0.5587, 0.5255, 0.3207, 0.4974,\n",
      "         0.4207, 0.4541, 0.4536, 0.5397, 0.5573, 0.4725, 0.6560, 0.4325, 0.5903,\n",
      "         0.5439, 0.4327, 0.6036],\n",
      "        [0.6345, 0.3662, 0.4641, 0.5427, 0.4968, 0.7218, 0.5261, 0.6640, 0.4238,\n",
      "         0.5142, 0.4245, 0.3751, 0.4314, 0.6247, 0.5118, 0.5932, 0.3763, 0.4459,\n",
      "         0.5752, 0.3900, 0.5134, 0.5505, 0.4745, 0.4194, 0.5485, 0.5403, 0.5443,\n",
      "         0.4796, 0.5833, 0.4083],\n",
      "        [0.4451, 0.6392, 0.5333, 0.4338, 0.3628, 0.5832, 0.4082, 0.5106, 0.4389,\n",
      "         0.5250, 0.5004, 0.3959, 0.4281, 0.4222, 0.6158, 0.5613, 0.5207, 0.5224,\n",
      "         0.5470, 0.4425, 0.4354, 0.4318, 0.6266, 0.5450, 0.4590, 0.3329, 0.3860,\n",
      "         0.4766, 0.4417, 0.4483],\n",
      "        [0.6533, 0.4439, 0.5971, 0.4993, 0.4150, 0.4874, 0.3595, 0.5263, 0.5396,\n",
      "         0.5278, 0.4256, 0.4645, 0.4574, 0.3694, 0.5148, 0.5295, 0.5298, 0.5845,\n",
      "         0.4922, 0.3845, 0.4603, 0.5362, 0.5826, 0.3713, 0.2774, 0.5517, 0.5070,\n",
      "         0.3960, 0.5193, 0.4725],\n",
      "        [0.5125, 0.6223, 0.5934, 0.5596, 0.5886, 0.4535, 0.3685, 0.4705, 0.5791,\n",
      "         0.4555, 0.5776, 0.5500, 0.5608, 0.4675, 0.3165, 0.5260, 0.4972, 0.4904,\n",
      "         0.5182, 0.5073, 0.4991, 0.6455, 0.4351, 0.4692, 0.6149, 0.4150, 0.4703,\n",
      "         0.5397, 0.4341, 0.5311],\n",
      "        [0.4717, 0.5580, 0.4380, 0.5999, 0.3095, 0.5652, 0.5507, 0.5282, 0.5825,\n",
      "         0.3466, 0.6415, 0.5418, 0.3808, 0.5240, 0.5044, 0.6135, 0.4537, 0.5324,\n",
      "         0.4920, 0.5769, 0.6404, 0.6132, 0.6145, 0.4630, 0.4077, 0.4959, 0.5449,\n",
      "         0.5367, 0.3940, 0.6361],\n",
      "        [0.5491, 0.5945, 0.4177, 0.4616, 0.3348, 0.4495, 0.5165, 0.6148, 0.4873,\n",
      "         0.6134, 0.5258, 0.6046, 0.4785, 0.5224, 0.3656, 0.5728, 0.6202, 0.3553,\n",
      "         0.3837, 0.5166, 0.3790, 0.5639, 0.5504, 0.5851, 0.5383, 0.2787, 0.4749,\n",
      "         0.7575, 0.3795, 0.5692],\n",
      "        [0.2466, 0.3821, 0.4419, 0.4429, 0.5681, 0.6313, 0.5470, 0.4985, 0.5390,\n",
      "         0.4783, 0.4200, 0.5445, 0.5550, 0.4511, 0.6995, 0.4224, 0.4883, 0.4615,\n",
      "         0.6509, 0.6289, 0.5538, 0.5138, 0.4006, 0.5439, 0.5917, 0.4666, 0.4116,\n",
      "         0.5784, 0.2803, 0.5683],\n",
      "        [0.3538, 0.4644, 0.3771, 0.4626, 0.4223, 0.4374, 0.4083, 0.5791, 0.4216,\n",
      "         0.4635, 0.4171, 0.5184, 0.4276, 0.4920, 0.5293, 0.3979, 0.6339, 0.3897,\n",
      "         0.7296, 0.4682, 0.3227, 0.3463, 0.6231, 0.5987, 0.4095, 0.3643, 0.4806,\n",
      "         0.5741, 0.5910, 0.5669],\n",
      "        [0.4606, 0.4486, 0.4106, 0.5495, 0.3648, 0.3876, 0.4259, 0.4251, 0.5618,\n",
      "         0.5567, 0.4276, 0.5685, 0.4748, 0.5592, 0.5370, 0.5047, 0.6270, 0.5994,\n",
      "         0.5741, 0.3979, 0.5622, 0.3670, 0.4058, 0.7017, 0.7050, 0.5058, 0.5042,\n",
      "         0.4529, 0.4190, 0.5628],\n",
      "        [0.4791, 0.5252, 0.5317, 0.3994, 0.5990, 0.5335, 0.5139, 0.5001, 0.4360,\n",
      "         0.4811, 0.4879, 0.5775, 0.5806, 0.6287, 0.4401, 0.4517, 0.5210, 0.4728,\n",
      "         0.5414, 0.3554, 0.5078, 0.5971, 0.6148, 0.3642, 0.4992, 0.4699, 0.4234,\n",
      "         0.6747, 0.4516, 0.4612],\n",
      "        [0.4682, 0.4770, 0.4164, 0.4009, 0.5498, 0.5606, 0.4858, 0.5295, 0.3666,\n",
      "         0.4896, 0.5180, 0.6563, 0.5480, 0.4757, 0.6006, 0.4311, 0.5665, 0.4881,\n",
      "         0.4888, 0.5947, 0.3847, 0.4815, 0.5088, 0.5433, 0.5672, 0.5635, 0.4560,\n",
      "         0.4596, 0.5808, 0.5751],\n",
      "        [0.4041, 0.5194, 0.5680, 0.7229, 0.4751, 0.5233, 0.5954, 0.3441, 0.5783,\n",
      "         0.5894, 0.5491, 0.5066, 0.4202, 0.4632, 0.4825, 0.4857, 0.5546, 0.3481,\n",
      "         0.4888, 0.5461, 0.6922, 0.4446, 0.3982, 0.5101, 0.4826, 0.4013, 0.5525,\n",
      "         0.5360, 0.5673, 0.4680],\n",
      "        [0.4703, 0.6081, 0.2635, 0.5005, 0.3849, 0.5433, 0.5614, 0.5282, 0.5313,\n",
      "         0.5135, 0.4108, 0.4025, 0.4930, 0.4737, 0.4909, 0.3207, 0.5727, 0.3145,\n",
      "         0.5091, 0.6238, 0.4237, 0.3810, 0.4149, 0.4954, 0.5028, 0.5088, 0.5570,\n",
      "         0.4458, 0.4378, 0.4553],\n",
      "        [0.6020, 0.5643, 0.3602, 0.5419, 0.5613, 0.5824, 0.6398, 0.4911, 0.4686,\n",
      "         0.4715, 0.5527, 0.4402, 0.4936, 0.4948, 0.4187, 0.5033, 0.5090, 0.4529,\n",
      "         0.4192, 0.4217, 0.6452, 0.3803, 0.3654, 0.5581, 0.6343, 0.4997, 0.5899,\n",
      "         0.5190, 0.4603, 0.6276],\n",
      "        [0.4758, 0.5204, 0.3811, 0.3215, 0.4907, 0.5126, 0.5782, 0.4625, 0.5520,\n",
      "         0.6380, 0.5565, 0.4035, 0.6031, 0.4286, 0.4661, 0.3119, 0.6957, 0.4536,\n",
      "         0.5413, 0.5995, 0.4939, 0.3008, 0.4555, 0.4676, 0.4095, 0.4429, 0.4483,\n",
      "         0.5689, 0.5011, 0.3653]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((5, 3, 256, 256))\n",
    "model = Discriminator(in_channels = 3)\n",
    "preds = model(x)\n",
    "print(preds.shape)\n",
    "print(preds[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, down = True, use_act = True, **kwargs):\n",
    "    super(ConvBlock, self).__init__()\n",
    "    self.conv = nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, padding_mode = 'reflect', **kwargs)\n",
    "        if down else \n",
    "        nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n",
    "        nn.InstanceNorm2d(out_channels),\n",
    "        nn.ReLU(inplace = True) if use_act else nn.Identity()\n",
    "    )\n",
    "  def forward(self, x):\n",
    "    return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "  def __init__(self, channels):\n",
    "    super(ResidualBlock, self).__init__()\n",
    "    self.block = nn.Sequential(\n",
    "      ConvBlock(channels, channels, kernel_size = 3, padding = 1),\n",
    "      ConvBlock(channels, channels, use_act = False, kernel_size = 3, padding = 1)\n",
    "  )\n",
    "  def forward(self, x):\n",
    "    return x + self.block(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 생성기 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "  def __init__(self, img_channels,num_features = 64, num_resblock = 9):\n",
    "    super(Generator, self).__init__()\n",
    "    self.initial = nn.Sequential(\n",
    "        nn.Conv2d(img_channels, num_features, kernel_size = 7, stride = 1, padding = 3, padding_mode = 'reflect'),\n",
    "        nn.ReLU(inplace = True)\n",
    "    )\n",
    "    self.down_blocks = nn.ModuleList(\n",
    "      [\n",
    "          ConvBlock(num_features, num_features * 2, kernel_size = 3, stride = 2, padding = 1),\n",
    "       ConvBlock(num_features * 2, num_features * 4, kernel_size = 3, stride = 2, padding = 1),]\n",
    "    )\n",
    "    self.residual_block = nn.Sequential(\n",
    "        *[ResidualBlock(num_features * 4) for _ in range(num_resblock)]\n",
    "    )\n",
    "\n",
    "    self.up_blocks = nn.ModuleList(\n",
    "        [\n",
    "        ConvBlock(num_features * 4, num_features * 2, down = False, kernel_size = 3, stride = 2,padding = 1, output_padding = 1),\n",
    "        ConvBlock(num_features * 2, num_features, down = False, kernel_size = 3, stride = 2,padding = 1, output_padding = 1)\n",
    "    ])\n",
    "    \n",
    "    self.last = nn.Conv2d(num_features * 1, img_channels, kernel_size = 7, stride = 1, padding = 3, padding_mode = 'reflect')\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.initial(x)\n",
    "    for layer in self.down_blocks:\n",
    "      x = layer(x)\n",
    "    x= self.residual_block(x)\n",
    "    for layer in self.up_blocks:\n",
    "      x = layer(x)\n",
    "    \n",
    "    return torch.tanh(self.last(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "test = torch.randn(2, 3, 256, 256)\n",
    "gen = Generator(3)\n",
    "print(gen(test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_ = [transforms.Resize(256),\n",
    "                                  transforms.RandomHorizontalFlip(),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "test_trans = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋은 celeb attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Dataset(Dataset):\n",
    "  def __init__(self, root, transforms_ = None, mode = 'train'):\n",
    "    self.transforms = transforms.Compose(transforms_)\n",
    "    \n",
    "    self.file_A = sorted(glob.glob(os.path.join(root, 'trainA') + '/*')) \n",
    "    self.file_B = sorted(glob.glob(os.path.join(root, 'trainB') + '/*'))\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    itemA = self.transforms(Image.open(self.file_A[index % len(self.file_A)]))\n",
    "\n",
    "    itemB = self.transforms(Image.open(self.file_B[index % len(self.file_B)]))\n",
    "\n",
    "    return {'A' : itemA, 'B' : itemB}\n",
    "\n",
    "  def __len__(self):\n",
    "    return max(len(self.file_A), len(self.file_B))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "root= \"D:\\\\다운로드\\\\archive 2\\\\img_align_celeba\\\\img_align_celeba\\\\\"\n",
    "batch_size = 32\n",
    "learning_rate = 2e-4\n",
    "lambda_identity = 0\n",
    "lambda_cycle = 10\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m disc_H \u001b[39m=\u001b[39m Discriminator(in_channels \u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m)\u001b[39m.\u001b[39;49mto(device)\n\u001b[0;32m      2\u001b[0m disc_Z \u001b[39m=\u001b[39m Discriminator(in_channels \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      3\u001b[0m gen_Z \u001b[39m=\u001b[39m Generator(img_channels \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m, num_resblock \u001b[39m=\u001b[39m \u001b[39m9\u001b[39m)\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\d2r2\\anaconda3\\envs\\celeb\\lib\\site-packages\\torch\\nn\\modules\\module.py:989\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    985\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    986\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m    987\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m--> 989\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[1;32mc:\\Users\\d2r2\\anaconda3\\envs\\celeb\\lib\\site-packages\\torch\\nn\\modules\\module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\d2r2\\anaconda3\\envs\\celeb\\lib\\site-packages\\torch\\nn\\modules\\module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\d2r2\\anaconda3\\envs\\celeb\\lib\\site-packages\\torch\\nn\\modules\\module.py:664\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    660\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    661\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    662\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    663\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 664\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    665\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    666\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32mc:\\Users\\d2r2\\anaconda3\\envs\\celeb\\lib\\site-packages\\torch\\nn\\modules\\module.py:987\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    984\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[0;32m    985\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    986\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m--> 987\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "File \u001b[1;32mc:\\Users\\d2r2\\anaconda3\\envs\\celeb\\lib\\site-packages\\torch\\cuda\\__init__.py:221\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    218\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    220\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 221\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    222\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m    224\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "disc_H = Discriminator(in_channels = 3).to(device)\n",
    "disc_Z = Discriminator(in_channels = 3).to(device)\n",
    "gen_Z = Generator(img_channels = 3, num_resblock = 9).to(device)\n",
    "gen_H = Generator(img_channels = 3, num_resblock = 9).to(device)\n",
    "\n",
    "optim_disc = optim.Adam(list(disc_H.parameters()) + list(disc_Z.parameters()),\n",
    "                        lr = learning_rate, betas = (0.5, 0.999))\n",
    "optim_gen = optim.Adam(list(gen_Z.parameters()) + list(gen_H.parameters()),\n",
    "                       lr = learning_rate, betas = (0.5, 0.999))\n",
    "L1 = nn.L1Loss()\n",
    "mse = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m dataset \u001b[39m=\u001b[39m Custom_Dataset(\n\u001b[0;32m      2\u001b[0m      root, transforms_ \u001b[39m=\u001b[39m transforms_\n\u001b[0;32m      3\u001b[0m )\n\u001b[1;32m----> 4\u001b[0m dataloader \u001b[39m=\u001b[39m DataLoader(dataset, batch_size \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m, shuffle \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\d2r2\\anaconda3\\envs\\celeb\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:344\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# map-style\u001b[39;00m\n\u001b[0;32m    343\u001b[0m     \u001b[39mif\u001b[39;00m shuffle:\n\u001b[1;32m--> 344\u001b[0m         sampler \u001b[39m=\u001b[39m RandomSampler(dataset, generator\u001b[39m=\u001b[39;49mgenerator)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    345\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    346\u001b[0m         sampler \u001b[39m=\u001b[39m SequentialSampler(dataset)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\d2r2\\anaconda3\\envs\\celeb\\lib\\site-packages\\torch\\utils\\data\\sampler.py:107\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mreplacement should be a boolean value, but got \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    104\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mreplacement=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplacement))\n\u001b[0;32m    106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples, \u001b[39mint\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 107\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mnum_samples should be a positive integer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mvalue, but got num_samples=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples))\n",
      "\u001b[1;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "dataset = Custom_Dataset(\n",
    "     root, transforms_ = transforms_\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size = 2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagea = iter.next((dataloader))['A'][1]\n",
    "imageb = iter.next((dataloader))['B'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(torchvision.utils.make_grid(imagea, normalize = True).permute(1, 2, 0)) #a에는 사과\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(torchvision.utils.make_grid(imageb, normalize = True).permute(1, 2, 0)) #b은 오렌지가 들어있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imagea.size())\n",
    "print(imageb.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "  for idx, batch in enumerate(dataloader):\n",
    "  \n",
    "    orange = batch['B'].to(device)\n",
    "    apple = batch['A'].to(device)\n",
    "    optim_disc.zero_grad()\n",
    "    optim_gen.zero_grad()\n",
    "\n",
    "    fake_apple = gen_A(orange) \n",
    "    D_A_real = disc_A(horse) \n",
    "    D_A_fake = disc_A(fake_horse.detach()) \n",
    "    D_A_real_loss = mse(D_A_real, torch.ones_like(D_A_real))\n",
    "    D_A_fake_loss = mse(D_A_fake, torch.zeros_like(D_A_fake)) \n",
    "    D_A_loss = D_A_real_loss + D_A_fake_loss \n",
    "\n",
    "    fake_orange = gen_O(apple)\n",
    "    D_O_real = disc_Z(zebra)\n",
    "    D_O_fake = disc_Z(fake_zebra.detach())\n",
    "    D_O_real_loss = mse(D_O_real, torch.ones_like(D_O_real))\n",
    "    D_O_fake_loss = mse(D_O_fake, torch.zeros_like(D_O_fake))\n",
    "    D_O_loss = D_O_real_loss + D_O_fake_loss\n",
    "\n",
    "    D_loss = (D_A_loss + D_O_loss) / 2\n",
    "\n",
    "    D_loss.backward()\n",
    "    optim_disc.step()\n",
    "    #generator 학습\n",
    "    D_A_fake = disc_A(fake_apple)\n",
    "    D_O_fake = disc_O(fake_orange)\n",
    "    loss_G_A = mse(D_Z_fake, torch.ones_like(D_A_fake)) #CE 를 쓰지않고 여기서 정의된 새로운 손실함수 \n",
    "    loss_G_O = mse(D_Z_fake, torch.ones_like(D_O_fake))\n",
    "\n",
    "    cycle_orange = gen_O(fake_apple)\n",
    "    cycle_apple = gen_A(fake_orange)\n",
    "    cycle_orange_loss = L1(orange, cycle_orange)\n",
    "    cycle_apple_loss = L1(apple, cycle_apple)\n",
    "\n",
    "    identity_orange = gen_O(orange)\n",
    "    identity_apple = gen_A(apple)\n",
    "    identity_orange_loss = L1(orange, identity_orange)\n",
    "    identity_apple_loss = L1(apple, identity_apple)\n",
    "\n",
    "    G_loss = (loss_G_O + loss_G_A + cycle_orange_loss * lambda_cycle + cycle_apple_loss * lambda_cycle\n",
    "              +identity_apple_loss * lambda_identity + identity_orange_loss * lambda_identity)\n",
    "    G_loss.backward()\n",
    "    optim_gen.step()\n",
    "    if idx == 50:\n",
    "      print('EPOCH : ', epoch, 'G_loss : ', G_loss, 'D_loss :', D_loss)\n",
    "      break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gen_A, 'gen_H.pt')\n",
    "torch.save(gen_O, 'gen_Z.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_image = iter(dataloader).next()['A'][1]\n",
    "orange_image = iter(dataloader).next()['B'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_image = apple_image.to(device)\n",
    "orange_image = orange_image.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델에 이미지 넣어서 결과 확인.\n",
    "나름 잘 변환된 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(torchvision.utils.make_grid(apple_image.cpu(), normalize = True).permute(1, 2, 0)) \n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(torchvision.utils.make_grid(orange_image.cpu(), normalize = True).permute(1, 2, 0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_apple = gen_H(orange_image).cpu()\n",
    "plt.imshow(torchvision.utils.make_grid(trans_apple.cpu(), normalize = True).permute(1, 2, 0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_orange = gen_Z(apple_image).cpu()\n",
    "plt.imshow(torchvision.utils.make_grid(trans_orange.cpu(), normalize = True).permute(1, 2, 0)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "celeb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54b35b3adbbd70330d6102a494230c62f4578d0a77ac8239ed45d9ee8bea0e04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, stride):\n",
    "    super(Block, self).__init__()\n",
    "    self.conv = nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 4, stride, 1, bias = True, padding_mode = 'reflect'),\n",
    "        nn.InstanceNorm2d(out_channels),\n",
    "        nn.LeakyReLU(0.2)\n",
    "    )\n",
    "  def forward(self, x):\n",
    "    return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "  def __init__(self, in_channels = 3, features = [64, 128, 256, 512]):\n",
    "    super(Discriminator, self).__init__()\n",
    "    self.initial = nn.Sequential(\n",
    "        nn.Conv2d(in_channels, features[0], kernel_size = 4, stride = 2, padding = 1, padding_mode ='reflect'), # Conv(3, 64, 4, 2, 1)\n",
    "    nn.LeakyReLU(0.2))\n",
    "\n",
    "    layers = []\n",
    "    in_channels = features[0]\n",
    "    for feature in features[1:]:\n",
    "      layers.append(Block(in_channels, feature, stride = 1 if feature == features[-1] else 2)) #Conv(64,128, 4, 2, 1),Conv(128,256, 4, 2, 1), Conv(256, 512, 4, 1, 1)  담는다\n",
    "      in_channels = feature # \n",
    "    layers.append(nn.Conv2d(in_channels,1, kernel_size = 4, stride = 1, padding = 1, padding_mode = 'reflect')) #Conv(512, 1, 4, 1, 1)\n",
    "    self.model = nn.Sequential(*layers)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.initial(x)\n",
    "    return torch.sigmoid(self.model(x)) # 30 x 30 pathgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 30, 30])\n",
      "tensor([[0.3997, 0.4635, 0.3825, 0.5762, 0.4164, 0.5671, 0.5631, 0.4284, 0.5155,\n",
      "         0.4465, 0.3008, 0.4125, 0.6461, 0.3669, 0.5287, 0.3254, 0.3260, 0.5202,\n",
      "         0.5438, 0.5735, 0.4327, 0.5066, 0.4545, 0.4391, 0.4005, 0.5319, 0.4182,\n",
      "         0.3856, 0.4044, 0.3371],\n",
      "        [0.4296, 0.3853, 0.3748, 0.4903, 0.4241, 0.5474, 0.2968, 0.6216, 0.4105,\n",
      "         0.4608, 0.4702, 0.3213, 0.4719, 0.3711, 0.2722, 0.4946, 0.5077, 0.4899,\n",
      "         0.3581, 0.3996, 0.6745, 0.5588, 0.5144, 0.5302, 0.5815, 0.4528, 0.3726,\n",
      "         0.3200, 0.4719, 0.4872],\n",
      "        [0.5392, 0.5690, 0.3816, 0.4496, 0.5237, 0.6391, 0.4891, 0.5576, 0.3496,\n",
      "         0.5032, 0.4880, 0.3674, 0.6315, 0.5784, 0.5499, 0.5230, 0.3261, 0.4750,\n",
      "         0.3534, 0.5026, 0.6153, 0.5265, 0.4416, 0.6719, 0.5822, 0.5177, 0.5683,\n",
      "         0.4058, 0.2487, 0.4515],\n",
      "        [0.5151, 0.6575, 0.4452, 0.6741, 0.3999, 0.4591, 0.4490, 0.4454, 0.5137,\n",
      "         0.4790, 0.5723, 0.6446, 0.5547, 0.4174, 0.5352, 0.3960, 0.3896, 0.4883,\n",
      "         0.5791, 0.3747, 0.5751, 0.3828, 0.4004, 0.5714, 0.3326, 0.4360, 0.4007,\n",
      "         0.4560, 0.4914, 0.4456],\n",
      "        [0.5259, 0.5670, 0.3635, 0.4493, 0.4428, 0.5369, 0.5310, 0.5129, 0.6422,\n",
      "         0.4777, 0.5853, 0.5618, 0.5022, 0.5989, 0.3146, 0.5485, 0.5027, 0.5582,\n",
      "         0.3056, 0.4453, 0.4516, 0.4224, 0.4385, 0.5760, 0.4861, 0.4764, 0.5227,\n",
      "         0.5150, 0.4393, 0.5712],\n",
      "        [0.3028, 0.5139, 0.4345, 0.4046, 0.5309, 0.6192, 0.5006, 0.7354, 0.6237,\n",
      "         0.4449, 0.6391, 0.4786, 0.4454, 0.3582, 0.4597, 0.4564, 0.4540, 0.5359,\n",
      "         0.5190, 0.7078, 0.4137, 0.5196, 0.4017, 0.4980, 0.3163, 0.3859, 0.5935,\n",
      "         0.3826, 0.3978, 0.4840],\n",
      "        [0.3980, 0.4776, 0.4035, 0.5196, 0.4874, 0.5890, 0.4560, 0.4001, 0.5170,\n",
      "         0.5565, 0.4357, 0.5067, 0.3630, 0.5451, 0.5129, 0.3315, 0.5346, 0.5182,\n",
      "         0.5376, 0.3993, 0.5034, 0.6127, 0.5216, 0.5577, 0.4109, 0.5427, 0.6104,\n",
      "         0.4963, 0.5395, 0.4257],\n",
      "        [0.3627, 0.4128, 0.3662, 0.4432, 0.5354, 0.4618, 0.5500, 0.6822, 0.4542,\n",
      "         0.5791, 0.4261, 0.4828, 0.5952, 0.4535, 0.3901, 0.4709, 0.3552, 0.5434,\n",
      "         0.4130, 0.4321, 0.4643, 0.4663, 0.5127, 0.4137, 0.4376, 0.4285, 0.3688,\n",
      "         0.4638, 0.4525, 0.3692],\n",
      "        [0.4698, 0.5186, 0.4743, 0.5174, 0.5015, 0.6297, 0.6534, 0.3266, 0.4427,\n",
      "         0.4463, 0.6020, 0.3132, 0.4862, 0.5797, 0.6019, 0.4412, 0.6907, 0.5645,\n",
      "         0.4519, 0.4707, 0.4386, 0.4381, 0.5171, 0.4873, 0.4647, 0.3872, 0.4815,\n",
      "         0.3831, 0.5709, 0.5722],\n",
      "        [0.4341, 0.3993, 0.4307, 0.4395, 0.5454, 0.4790, 0.3832, 0.4919, 0.4630,\n",
      "         0.5435, 0.5300, 0.6256, 0.4890, 0.5436, 0.5985, 0.3109, 0.4376, 0.4418,\n",
      "         0.6018, 0.4900, 0.6516, 0.5711, 0.3103, 0.3963, 0.4013, 0.5860, 0.3351,\n",
      "         0.4504, 0.5730, 0.5620],\n",
      "        [0.4342, 0.4875, 0.4847, 0.5037, 0.4625, 0.5107, 0.4264, 0.2585, 0.4230,\n",
      "         0.5332, 0.5184, 0.5452, 0.4586, 0.3394, 0.4813, 0.5988, 0.3995, 0.5907,\n",
      "         0.3633, 0.3924, 0.5020, 0.4294, 0.4408, 0.5737, 0.5438, 0.4518, 0.5664,\n",
      "         0.2589, 0.5623, 0.4150],\n",
      "        [0.2858, 0.5810, 0.4121, 0.3460, 0.5255, 0.5377, 0.3650, 0.4813, 0.3891,\n",
      "         0.3843, 0.5689, 0.6431, 0.3180, 0.5312, 0.4305, 0.5162, 0.5746, 0.4418,\n",
      "         0.3183, 0.3904, 0.4767, 0.3644, 0.4491, 0.3164, 0.5978, 0.4742, 0.5662,\n",
      "         0.3687, 0.4690, 0.4359],\n",
      "        [0.4942, 0.6036, 0.3186, 0.5601, 0.4360, 0.5753, 0.6038, 0.5428, 0.5593,\n",
      "         0.3596, 0.5018, 0.5349, 0.6144, 0.3538, 0.6586, 0.3585, 0.4550, 0.3025,\n",
      "         0.4265, 0.3641, 0.5228, 0.4014, 0.5861, 0.4730, 0.2901, 0.4293, 0.5208,\n",
      "         0.6113, 0.5178, 0.5556],\n",
      "        [0.5546, 0.4897, 0.4288, 0.6492, 0.4766, 0.3987, 0.5279, 0.3688, 0.5563,\n",
      "         0.5990, 0.6188, 0.4188, 0.5017, 0.6157, 0.5041, 0.5800, 0.3318, 0.3847,\n",
      "         0.5482, 0.5266, 0.4271, 0.3675, 0.5723, 0.5650, 0.3697, 0.3992, 0.4187,\n",
      "         0.6176, 0.4949, 0.4576],\n",
      "        [0.4148, 0.4335, 0.4232, 0.5544, 0.4062, 0.4032, 0.5608, 0.5580, 0.3245,\n",
      "         0.5019, 0.4665, 0.4666, 0.4563, 0.5828, 0.4592, 0.4301, 0.4325, 0.5858,\n",
      "         0.4733, 0.5522, 0.4597, 0.5439, 0.4240, 0.6411, 0.3028, 0.5498, 0.4377,\n",
      "         0.4017, 0.5849, 0.4142],\n",
      "        [0.4022, 0.6104, 0.2735, 0.4649, 0.4276, 0.5126, 0.3258, 0.5650, 0.4894,\n",
      "         0.4204, 0.4692, 0.4659, 0.5156, 0.4606, 0.5614, 0.5670, 0.3197, 0.3960,\n",
      "         0.5103, 0.5140, 0.4354, 0.3583, 0.3943, 0.3785, 0.3190, 0.5742, 0.4649,\n",
      "         0.3339, 0.4368, 0.5638],\n",
      "        [0.5145, 0.4701, 0.4275, 0.4086, 0.5169, 0.4520, 0.4562, 0.5024, 0.5570,\n",
      "         0.4881, 0.3518, 0.3854, 0.3859, 0.6663, 0.3889, 0.6019, 0.5917, 0.3202,\n",
      "         0.4217, 0.2858, 0.6120, 0.3616, 0.5899, 0.4782, 0.6731, 0.4260, 0.5285,\n",
      "         0.5064, 0.4182, 0.4715],\n",
      "        [0.4727, 0.5297, 0.5782, 0.4640, 0.3512, 0.4821, 0.4599, 0.4589, 0.6348,\n",
      "         0.3731, 0.3815, 0.4850, 0.6111, 0.4466, 0.3672, 0.4801, 0.4140, 0.4681,\n",
      "         0.4959, 0.5061, 0.4489, 0.4160, 0.4881, 0.4879, 0.3983, 0.3689, 0.4087,\n",
      "         0.4672, 0.5062, 0.5116],\n",
      "        [0.4812, 0.4739, 0.4190, 0.4198, 0.5650, 0.5832, 0.5092, 0.4010, 0.4528,\n",
      "         0.4391, 0.4585, 0.5076, 0.4346, 0.6124, 0.5804, 0.4073, 0.3528, 0.4654,\n",
      "         0.4366, 0.4774, 0.3638, 0.3903, 0.4034, 0.6092, 0.3499, 0.6134, 0.6726,\n",
      "         0.2829, 0.6086, 0.5232],\n",
      "        [0.5213, 0.5898, 0.4795, 0.5990, 0.5002, 0.5609, 0.4109, 0.4634, 0.5145,\n",
      "         0.6130, 0.4884, 0.4854, 0.5465, 0.4283, 0.4209, 0.3788, 0.4398, 0.4151,\n",
      "         0.3090, 0.4610, 0.4992, 0.5657, 0.4798, 0.3464, 0.5368, 0.6908, 0.4588,\n",
      "         0.5734, 0.3582, 0.3641],\n",
      "        [0.5752, 0.4982, 0.6123, 0.6968, 0.4177, 0.3703, 0.4726, 0.6180, 0.3804,\n",
      "         0.5529, 0.6366, 0.4729, 0.5088, 0.3616, 0.5535, 0.5019, 0.6407, 0.3957,\n",
      "         0.5260, 0.3958, 0.4411, 0.5367, 0.3388, 0.4418, 0.5100, 0.3212, 0.4895,\n",
      "         0.4690, 0.4029, 0.4724],\n",
      "        [0.4408, 0.4420, 0.5282, 0.5200, 0.4927, 0.5124, 0.5021, 0.3448, 0.5766,\n",
      "         0.5135, 0.5563, 0.4984, 0.4437, 0.4950, 0.5194, 0.3027, 0.3784, 0.4756,\n",
      "         0.5030, 0.4220, 0.4330, 0.3354, 0.3322, 0.4415, 0.6338, 0.4050, 0.6528,\n",
      "         0.3784, 0.5467, 0.5825],\n",
      "        [0.6374, 0.4329, 0.5308, 0.4351, 0.5081, 0.4749, 0.3603, 0.4728, 0.5742,\n",
      "         0.5300, 0.5929, 0.4480, 0.4905, 0.4768, 0.4476, 0.3854, 0.4911, 0.5485,\n",
      "         0.4232, 0.4562, 0.4099, 0.5193, 0.5071, 0.4205, 0.6410, 0.3175, 0.4674,\n",
      "         0.4500, 0.4296, 0.5955],\n",
      "        [0.6381, 0.4875, 0.6818, 0.4918, 0.3629, 0.6467, 0.4919, 0.4913, 0.4454,\n",
      "         0.4933, 0.4896, 0.5116, 0.4751, 0.3846, 0.5331, 0.5430, 0.4086, 0.4562,\n",
      "         0.4766, 0.5731, 0.5266, 0.5184, 0.4680, 0.6204, 0.4661, 0.4568, 0.2003,\n",
      "         0.4127, 0.3925, 0.4617],\n",
      "        [0.4191, 0.4357, 0.5235, 0.2265, 0.5530, 0.5517, 0.3673, 0.3883, 0.5671,\n",
      "         0.4097, 0.5052, 0.5543, 0.4209, 0.4087, 0.4564, 0.5274, 0.5526, 0.4496,\n",
      "         0.5284, 0.4247, 0.5469, 0.3983, 0.4497, 0.4410, 0.5028, 0.4027, 0.4269,\n",
      "         0.5112, 0.3917, 0.5609],\n",
      "        [0.6508, 0.5159, 0.4988, 0.3160, 0.5925, 0.3797, 0.4951, 0.5568, 0.4419,\n",
      "         0.4295, 0.4667, 0.3165, 0.6165, 0.5257, 0.4421, 0.4740, 0.3790, 0.4723,\n",
      "         0.4453, 0.3745, 0.4341, 0.6227, 0.5302, 0.4519, 0.5202, 0.5840, 0.3501,\n",
      "         0.4966, 0.5088, 0.5175],\n",
      "        [0.4159, 0.5438, 0.4337, 0.3097, 0.5126, 0.5451, 0.5000, 0.6164, 0.4755,\n",
      "         0.5330, 0.3629, 0.3682, 0.5052, 0.4837, 0.3070, 0.4089, 0.6192, 0.6118,\n",
      "         0.4761, 0.3759, 0.5086, 0.4958, 0.6511, 0.6148, 0.5919, 0.5093, 0.4137,\n",
      "         0.6449, 0.4578, 0.4441],\n",
      "        [0.5293, 0.4900, 0.4754, 0.4296, 0.4136, 0.5767, 0.4362, 0.4844, 0.5093,\n",
      "         0.4319, 0.4922, 0.5557, 0.4411, 0.6694, 0.4557, 0.4281, 0.4783, 0.6777,\n",
      "         0.5813, 0.4036, 0.6232, 0.2878, 0.3752, 0.4208, 0.5771, 0.3936, 0.5690,\n",
      "         0.6267, 0.5745, 0.5216],\n",
      "        [0.4890, 0.4627, 0.5325, 0.6113, 0.3306, 0.3788, 0.4821, 0.5746, 0.4835,\n",
      "         0.6346, 0.4264, 0.4862, 0.4490, 0.4311, 0.4771, 0.5215, 0.4999, 0.5487,\n",
      "         0.4693, 0.4473, 0.6153, 0.5743, 0.3939, 0.5896, 0.4442, 0.5822, 0.5370,\n",
      "         0.5232, 0.5353, 0.3764],\n",
      "        [0.6323, 0.4958, 0.4393, 0.5001, 0.5513, 0.5571, 0.3883, 0.5094, 0.5712,\n",
      "         0.4623, 0.5086, 0.3846, 0.3476, 0.6111, 0.4379, 0.4127, 0.4267, 0.5831,\n",
      "         0.4059, 0.5570, 0.4838, 0.3679, 0.5112, 0.3254, 0.5966, 0.4763, 0.5627,\n",
      "         0.5346, 0.5536, 0.4687]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((5, 3, 256, 256))\n",
    "model = Discriminator(in_channels = 3)\n",
    "preds = model(x)\n",
    "print(preds.shape)\n",
    "print(preds[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, down = True, use_act = True, **kwargs):\n",
    "    super(ConvBlock, self).__init__()\n",
    "    self.conv = nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, padding_mode = 'reflect', **kwargs)\n",
    "        if down else \n",
    "        nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n",
    "        nn.InstanceNorm2d(out_channels),\n",
    "        nn.ReLU(inplace = True) if use_act else nn.Identity()\n",
    "    )\n",
    "  def forward(self, x):\n",
    "    return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "  def __init__(self, channels):\n",
    "    super(ResidualBlock, self).__init__()\n",
    "    self.block = nn.Sequential(\n",
    "      ConvBlock(channels, channels, kernel_size = 3, padding = 1),\n",
    "      ConvBlock(channels, channels, use_act = False, kernel_size = 3, padding = 1)\n",
    "  )\n",
    "  def forward(self, x):\n",
    "    return x + self.block(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 생성기 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "  def __init__(self, img_channels,num_features = 64, num_resblock = 9):\n",
    "    super(Generator, self).__init__()\n",
    "    self.initial = nn.Sequential(\n",
    "        nn.Conv2d(img_channels, num_features, kernel_size = 7, stride = 1, padding = 3, padding_mode = 'reflect'),\n",
    "        nn.ReLU(inplace = True)\n",
    "    )\n",
    "    self.down_blocks = nn.ModuleList(\n",
    "      [\n",
    "          ConvBlock(num_features, num_features * 2, kernel_size = 3, stride = 2, padding = 1),\n",
    "       ConvBlock(num_features * 2, num_features * 4, kernel_size = 3, stride = 2, padding = 1),]\n",
    "    )\n",
    "    self.residual_block = nn.Sequential(\n",
    "        *[ResidualBlock(num_features * 4) for _ in range(num_resblock)]\n",
    "    )\n",
    "\n",
    "    self.up_blocks = nn.ModuleList(\n",
    "        [\n",
    "        ConvBlock(num_features * 4, num_features * 2, down = False, kernel_size = 3, stride = 2,padding = 1, output_padding = 1),\n",
    "        ConvBlock(num_features * 2, num_features, down = False, kernel_size = 3, stride = 2,padding = 1, output_padding = 1)\n",
    "    ])\n",
    "    \n",
    "    self.last = nn.Conv2d(num_features * 1, img_channels, kernel_size = 7, stride = 1, padding = 3, padding_mode = 'reflect')\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.initial(x)\n",
    "    for layer in self.down_blocks:\n",
    "      x = layer(x)\n",
    "    x= self.residual_block(x)\n",
    "    for layer in self.up_blocks:\n",
    "      x = layer(x)\n",
    "    \n",
    "    return torch.tanh(self.last(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "test = torch.randn(2, 3, 256, 256)\n",
    "gen = Generator(3)\n",
    "print(gen(test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_ = [transforms.Resize(256),\n",
    "                                  transforms.RandomHorizontalFlip(),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "test_trans = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋은 celeb attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Dataset(Dataset):\n",
    "  def __init__(self, root, transforms_ = None, mode = 'train'):\n",
    "    self.transforms = transforms.Compose(transforms_)\n",
    "    \n",
    "    self.file_A = sorted(glob.glob(os.path.join(root, 'trainA') + '/*')) \n",
    "    self.file_B = sorted(glob.glob(os.path.join(root, 'trainB') + '/*'))\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    itemA = self.transforms(Image.open(self.file_A[index % len(self.file_A)]))\n",
    "\n",
    "    itemB = self.transforms(Image.open(self.file_B[index % len(self.file_B)]))\n",
    "\n",
    "    return {'A' : itemA, 'B' : itemB}\n",
    "\n",
    "  def __len__(self):\n",
    "    return max(len(self.file_A), len(self.file_B))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#root= \"C:\\\\Users\\\\User\\\\Desktop\\\\GAN proj\\\\archive\\\\img_align_celeba\\\\img_align_celeba_AB\\\\\"\n",
    "root = \"D:\\\\다운로드\\\\archive\\\\dataAB\\\\\"\n",
    "batch_size = 32\n",
    "learning_rate = 2e-4\n",
    "lambda_identity = 0\n",
    "lambda_cycle = 10\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_H = Discriminator(in_channels = 3).to(device)\n",
    "disc_Z = Discriminator(in_channels = 3).to(device)\n",
    "gen_Z = Generator(img_channels = 3, num_resblock = 9).to(device)\n",
    "gen_H = Generator(img_channels = 3, num_resblock = 9).to(device)\n",
    "\n",
    "optim_disc = optim.Adam(list(disc_H.parameters()) + list(disc_Z.parameters()),\n",
    "                        lr = learning_rate, betas = (0.5, 0.999))\n",
    "optim_gen = optim.Adam(list(gen_Z.parameters()) + list(gen_H.parameters()),\n",
    "                       lr = learning_rate, betas = (0.5, 0.999))\n",
    "L1 = nn.L1Loss()\n",
    "mse = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Custom_Dataset(\n",
    "     root, transforms_ = transforms_\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size = 2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagea = next(iter(dataloader))['A'][0]\n",
    "imageb = next(iter(dataloader))['B'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0353,  0.0275,  0.0275,  ...,  0.3020,  0.3020,  0.3020],\n",
       "         [ 0.0353,  0.0275,  0.0275,  ...,  0.3020,  0.3020,  0.3020],\n",
       "         [ 0.0353,  0.0275,  0.0275,  ...,  0.3020,  0.3020,  0.3020],\n",
       "         ...,\n",
       "         [ 0.2078,  0.2078,  0.2078,  ...,  0.5529,  0.5529,  0.5529],\n",
       "         [ 0.2078,  0.2078,  0.2078,  ...,  0.5529,  0.5529,  0.5529],\n",
       "         [ 0.2078,  0.2078,  0.2078,  ...,  0.5529,  0.5529,  0.5529]],\n",
       "\n",
       "        [[-0.0118, -0.0196, -0.0196,  ...,  0.2784,  0.2784,  0.2784],\n",
       "         [-0.0118, -0.0196, -0.0196,  ...,  0.2784,  0.2784,  0.2784],\n",
       "         [-0.0118, -0.0196, -0.0196,  ...,  0.2784,  0.2784,  0.2784],\n",
       "         ...,\n",
       "         [-0.5373, -0.5373, -0.5373,  ...,  0.5922,  0.5922,  0.5922],\n",
       "         [-0.5373, -0.5373, -0.5373,  ...,  0.5922,  0.5922,  0.5922],\n",
       "         [-0.5373, -0.5373, -0.5373,  ...,  0.5922,  0.5922,  0.5922]],\n",
       "\n",
       "        [[-0.1843, -0.1922, -0.1922,  ..., -0.1373, -0.1373, -0.1373],\n",
       "         [-0.1843, -0.1922, -0.1922,  ..., -0.1373, -0.1373, -0.1373],\n",
       "         [-0.1843, -0.1922, -0.1922,  ..., -0.1373, -0.1373, -0.1373],\n",
       "         ...,\n",
       "         [-0.7569, -0.7569, -0.7569,  ...,  0.5373,  0.5373,  0.5373],\n",
       "         [-0.7569, -0.7569, -0.7569,  ...,  0.5373,  0.5373,  0.5373],\n",
       "         [-0.7569, -0.7569, -0.7569,  ...,  0.5373,  0.5373,  0.5373]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 313, 256])\n",
      "torch.Size([3, 313, 256])\n"
     ]
    }
   ],
   "source": [
    "print(imagea.size())\n",
    "print(imageb.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gen_A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m optim_disc\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m      7\u001b[0m optim_gen\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m----> 9\u001b[0m fake_apple \u001b[39m=\u001b[39m gen_A(orange) \n\u001b[0;32m     10\u001b[0m D_A_real \u001b[39m=\u001b[39m disc_A(horse) \n\u001b[0;32m     11\u001b[0m D_A_fake \u001b[39m=\u001b[39m disc_A(fake_horse\u001b[39m.\u001b[39mdetach()) \n",
      "\u001b[1;31mNameError\u001b[0m: name 'gen_A' is not defined"
     ]
    }
   ],
   "source": [
    "# disc_H = Discriminator(in_channels = 3).to(device) = disc_A\n",
    "# disc_Z = Discriminator(in_channels = 3).to(device) = disc_O\n",
    "# gen_Z = Generator(img_channels = 3, num_resblock = 9).to(device) = gen_O\n",
    "# gen_H = Generator(img_channels = 3, num_resblock = 9).to(device) = gen_A\n",
    "# zebra = orange, horse = apple\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  for idx, batch in enumerate(dataloader):\n",
    "  \n",
    "    orange = batch['B'].to(device)\n",
    "    apple = batch['A'].to(device)\n",
    "    optim_disc.zero_grad()\n",
    "    optim_gen.zero_grad()\n",
    "\n",
    "    fake_apple = gen_H(orange) \n",
    "    D_A_real = disc_H(apple) \n",
    "    D_A_fake = disc_H(fake_apple.detach()) \n",
    "    D_A_real_loss = mse(D_A_real, torch.ones_like(D_A_real))\n",
    "    D_A_fake_loss = mse(D_A_fake, torch.zeros_like(D_A_fake)) \n",
    "    D_A_loss = D_A_real_loss + D_A_fake_loss \n",
    "\n",
    "    fake_orange = gen_Z(apple)\n",
    "    D_O_real = disc_Z(orange)\n",
    "    D_O_fake = disc_Z(fake_orange.detach())\n",
    "    D_O_real_loss = mse(D_O_real, torch.ones_like(D_O_real))\n",
    "    D_O_fake_loss = mse(D_O_fake, torch.zeros_like(D_O_fake))\n",
    "    D_O_loss = D_O_real_loss + D_O_fake_loss\n",
    "\n",
    "    D_loss = (D_A_loss + D_O_loss) / 2\n",
    "\n",
    "    D_loss.backward()\n",
    "    optim_disc.step()\n",
    "    #generator 학습\n",
    "    D_A_fake = disc_H(fake_apple)\n",
    "    D_O_fake = disc_Z(fake_orange)\n",
    "    loss_G_A = mse(D_O_fake, torch.ones_like(D_A_fake)) #CE 를 쓰지않고 여기서 정의된 새로운 손실함수 \n",
    "    loss_G_O = mse(D_O_fake, torch.ones_like(D_O_fake))\n",
    "\n",
    "    cycle_orange = gen_Z(fake_apple)\n",
    "    cycle_apple = gen_H(fake_orange)\n",
    "    cycle_orange_loss = L1(orange, cycle_orange)\n",
    "    cycle_apple_loss = L1(apple, cycle_apple)\n",
    "\n",
    "    identity_orange = gen_Z(orange)\n",
    "    identity_apple = gen_H(apple)\n",
    "    identity_orange_loss = L1(orange, identity_orange)\n",
    "    identity_apple_loss = L1(apple, identity_apple)\n",
    "\n",
    "    G_loss = (loss_G_O + loss_G_A + cycle_orange_loss * lambda_cycle + cycle_apple_loss * lambda_cycle\n",
    "              +identity_apple_loss * lambda_identity + identity_orange_loss * lambda_identity)\n",
    "    G_loss.backward()\n",
    "    optim_gen.step()\n",
    "    if idx == 50:\n",
    "      print('EPOCH : ', epoch, 'G_loss : ', G_loss, 'D_loss :', D_loss)\n",
    "      break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gen_H, 'gen_H.pt')\n",
    "torch.save(gen_Z, 'gen_Z.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_image = iter(dataloader).next()['A'][1]\n",
    "orange_image = iter(dataloader).next()['B'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_image = apple_image.to(device)\n",
    "orange_image = orange_image.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델에 이미지 넣어서 결과 확인.\n",
    "나름 잘 변환된 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(torchvision.utils.make_grid(apple_image.cpu(), normalize = True).permute(1, 2, 0)) \n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(torchvision.utils.make_grid(orange_image.cpu(), normalize = True).permute(1, 2, 0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_apple = gen_H(orange_image).cpu()\n",
    "plt.imshow(torchvision.utils.make_grid(trans_apple.cpu(), normalize = True).permute(1, 2, 0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_orange = gen_Z(apple_image).cpu()\n",
    "plt.imshow(torchvision.utils.make_grid(trans_orange.cpu(), normalize = True).permute(1, 2, 0)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GANproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 24 2022, 14:07:00) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a3c4cd00832f70cdac7ec7549acc19572d1216e77e58965fda5bf4cdfa335463"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

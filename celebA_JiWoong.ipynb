{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 정의 아아아"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, stride):\n",
    "    super(Block, self).__init__()\n",
    "    self.conv = nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 4, stride, 1, bias = True, padding_mode = 'reflect'),\n",
    "        nn.InstanceNorm2d(out_channels),\n",
    "        nn.LeakyReLU(0.2)\n",
    "    )\n",
    "  def forward(self, x):\n",
    "    return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "  def __init__(self, in_channels = 3, features = [64, 128, 256, 512]):\n",
    "    super(Discriminator, self).__init__()\n",
    "    self.initial = nn.Sequential(\n",
    "        nn.Conv2d(in_channels, features[0], kernel_size = 4, stride = 2, padding = 1, padding_mode ='reflect'), # Conv(3, 64, 4, 2, 1)\n",
    "    nn.LeakyReLU(0.2))\n",
    "\n",
    "    layers = []\n",
    "    in_channels = features[0]\n",
    "    for feature in features[1:]:\n",
    "      layers.append(Block(in_channels, feature, stride = 1 if feature == features[-1] else 2)) #Conv(64,128, 4, 2, 1),Conv(128,256, 4, 2, 1), Conv(256, 512, 4, 1, 1)  담는다\n",
    "      in_channels = feature # \n",
    "    layers.append(nn.Conv2d(in_channels,1, kernel_size = 4, stride = 1, padding = 1, padding_mode = 'reflect')) #Conv(512, 1, 4, 1, 1)\n",
    "    self.model = nn.Sequential(*layers)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.initial(x)\n",
    "    return torch.sigmoid(self.model(x)) # 30 x 30 pathgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 30, 30])\n",
      "tensor([[0.5561, 0.3657, 0.4835, 0.4924, 0.5773, 0.5630, 0.4704, 0.3763, 0.3001,\n",
      "         0.4534, 0.3602, 0.4322, 0.5858, 0.5686, 0.3794, 0.5431, 0.5584, 0.4641,\n",
      "         0.4170, 0.4669, 0.5012, 0.4426, 0.4585, 0.3972, 0.4223, 0.2979, 0.4902,\n",
      "         0.5283, 0.3980, 0.6258],\n",
      "        [0.5644, 0.4615, 0.5307, 0.4407, 0.4091, 0.5449, 0.4203, 0.3676, 0.3896,\n",
      "         0.5443, 0.5738, 0.3937, 0.6257, 0.2452, 0.3816, 0.4564, 0.5510, 0.2908,\n",
      "         0.4203, 0.4737, 0.4906, 0.5641, 0.5946, 0.5477, 0.5462, 0.4133, 0.4891,\n",
      "         0.4144, 0.3685, 0.6011],\n",
      "        [0.4524, 0.4451, 0.5739, 0.6200, 0.5065, 0.5107, 0.4986, 0.4448, 0.4707,\n",
      "         0.5559, 0.3115, 0.5202, 0.5463, 0.5241, 0.3327, 0.6150, 0.5331, 0.5415,\n",
      "         0.3981, 0.4293, 0.5357, 0.4540, 0.4625, 0.3155, 0.5107, 0.4716, 0.5205,\n",
      "         0.4446, 0.5269, 0.5126],\n",
      "        [0.5377, 0.6194, 0.4750, 0.5472, 0.3486, 0.5164, 0.5135, 0.3497, 0.5521,\n",
      "         0.4817, 0.5896, 0.5395, 0.3702, 0.4758, 0.5225, 0.5389, 0.5586, 0.3594,\n",
      "         0.3098, 0.3897, 0.5669, 0.5896, 0.4793, 0.5572, 0.6113, 0.3994, 0.6770,\n",
      "         0.4708, 0.4371, 0.3862],\n",
      "        [0.6096, 0.4303, 0.4986, 0.4854, 0.4477, 0.4788, 0.4162, 0.4564, 0.4050,\n",
      "         0.4656, 0.3719, 0.3692, 0.5083, 0.4512, 0.6911, 0.5297, 0.4932, 0.5536,\n",
      "         0.2934, 0.2977, 0.4759, 0.4561, 0.4954, 0.5821, 0.4385, 0.6228, 0.5763,\n",
      "         0.4261, 0.6666, 0.4563],\n",
      "        [0.4554, 0.4355, 0.6207, 0.4746, 0.6699, 0.4155, 0.3565, 0.5027, 0.4332,\n",
      "         0.4857, 0.5273, 0.4546, 0.5810, 0.4742, 0.3078, 0.4495, 0.5634, 0.4882,\n",
      "         0.5224, 0.5034, 0.5370, 0.4505, 0.4199, 0.4464, 0.5668, 0.3114, 0.5171,\n",
      "         0.6388, 0.6343, 0.6192],\n",
      "        [0.4143, 0.5592, 0.5092, 0.4800, 0.3879, 0.5611, 0.4538, 0.4006, 0.4921,\n",
      "         0.5151, 0.4380, 0.3547, 0.5905, 0.5274, 0.5033, 0.5100, 0.4171, 0.4411,\n",
      "         0.3879, 0.4660, 0.5238, 0.4465, 0.4189, 0.4569, 0.5625, 0.4540, 0.5159,\n",
      "         0.3992, 0.4898, 0.4182],\n",
      "        [0.4453, 0.3757, 0.4616, 0.6078, 0.5423, 0.4464, 0.5967, 0.4416, 0.5642,\n",
      "         0.5694, 0.6015, 0.6046, 0.5999, 0.5290, 0.5122, 0.3930, 0.6547, 0.4845,\n",
      "         0.4554, 0.4920, 0.6611, 0.4969, 0.5350, 0.6501, 0.4650, 0.3501, 0.5619,\n",
      "         0.5986, 0.4249, 0.4939],\n",
      "        [0.5007, 0.4718, 0.4164, 0.4567, 0.4218, 0.4894, 0.5260, 0.3550, 0.5433,\n",
      "         0.5046, 0.4674, 0.5329, 0.4498, 0.5827, 0.7107, 0.4630, 0.5381, 0.4190,\n",
      "         0.5215, 0.4185, 0.5472, 0.3802, 0.3528, 0.4492, 0.3881, 0.4373, 0.5023,\n",
      "         0.3597, 0.3795, 0.3708],\n",
      "        [0.5753, 0.4222, 0.4132, 0.5484, 0.5318, 0.6190, 0.5460, 0.5297, 0.3921,\n",
      "         0.7244, 0.4010, 0.4652, 0.3594, 0.3480, 0.4019, 0.3782, 0.4562, 0.5604,\n",
      "         0.6155, 0.3750, 0.4523, 0.4499, 0.4389, 0.4089, 0.6129, 0.4138, 0.5218,\n",
      "         0.6632, 0.4388, 0.5847],\n",
      "        [0.4474, 0.4733, 0.4665, 0.5583, 0.4390, 0.5341, 0.3577, 0.4949, 0.4875,\n",
      "         0.6242, 0.3920, 0.3978, 0.4234, 0.4445, 0.4534, 0.4082, 0.4083, 0.3925,\n",
      "         0.6445, 0.5201, 0.7220, 0.3870, 0.5937, 0.3995, 0.6211, 0.5046, 0.6552,\n",
      "         0.4916, 0.5904, 0.4648],\n",
      "        [0.3836, 0.5155, 0.4626, 0.4196, 0.4553, 0.4364, 0.5852, 0.5832, 0.5532,\n",
      "         0.5514, 0.5013, 0.5212, 0.4687, 0.4753, 0.5981, 0.5276, 0.5599, 0.4386,\n",
      "         0.6014, 0.6252, 0.5681, 0.6002, 0.4024, 0.6335, 0.4224, 0.4904, 0.4560,\n",
      "         0.5172, 0.5163, 0.5506],\n",
      "        [0.3474, 0.6217, 0.4001, 0.4062, 0.4765, 0.4381, 0.3881, 0.5782, 0.4178,\n",
      "         0.5138, 0.5699, 0.5256, 0.4320, 0.6273, 0.3242, 0.5222, 0.5285, 0.3434,\n",
      "         0.5000, 0.3465, 0.6123, 0.6364, 0.4236, 0.5346, 0.6817, 0.5235, 0.5656,\n",
      "         0.6179, 0.5322, 0.5037],\n",
      "        [0.5525, 0.4233, 0.5592, 0.3824, 0.4026, 0.4697, 0.4368, 0.5608, 0.5705,\n",
      "         0.4558, 0.3184, 0.4379, 0.4164, 0.4305, 0.3417, 0.4597, 0.5181, 0.4080,\n",
      "         0.4002, 0.3926, 0.3079, 0.5291, 0.5949, 0.5239, 0.6496, 0.4461, 0.5068,\n",
      "         0.6109, 0.5265, 0.4989],\n",
      "        [0.6020, 0.5894, 0.5022, 0.6020, 0.3093, 0.6903, 0.4843, 0.4947, 0.5360,\n",
      "         0.6539, 0.2304, 0.5645, 0.3579, 0.4828, 0.4796, 0.4091, 0.5292, 0.3692,\n",
      "         0.4568, 0.5234, 0.5727, 0.4727, 0.4116, 0.5330, 0.3875, 0.6754, 0.5407,\n",
      "         0.4552, 0.5885, 0.6404],\n",
      "        [0.5897, 0.4270, 0.4074, 0.5428, 0.3276, 0.4394, 0.4862, 0.4809, 0.2697,\n",
      "         0.4563, 0.4218, 0.5640, 0.5063, 0.5551, 0.4847, 0.5870, 0.3086, 0.4474,\n",
      "         0.4858, 0.5230, 0.4900, 0.5784, 0.6162, 0.5308, 0.5231, 0.5641, 0.5528,\n",
      "         0.4365, 0.5465, 0.3963],\n",
      "        [0.4380, 0.6618, 0.6910, 0.5019, 0.4930, 0.5110, 0.4693, 0.7228, 0.4443,\n",
      "         0.5209, 0.4147, 0.3779, 0.4548, 0.5132, 0.6715, 0.5300, 0.4080, 0.5038,\n",
      "         0.4921, 0.5141, 0.4036, 0.4729, 0.4677, 0.3674, 0.4417, 0.5995, 0.5212,\n",
      "         0.4972, 0.5048, 0.5994],\n",
      "        [0.5214, 0.4816, 0.5209, 0.5434, 0.6021, 0.2957, 0.5060, 0.3410, 0.4016,\n",
      "         0.4961, 0.3563, 0.4845, 0.5023, 0.6586, 0.5564, 0.4365, 0.5544, 0.5840,\n",
      "         0.5678, 0.3897, 0.4538, 0.5003, 0.4510, 0.5182, 0.5354, 0.6161, 0.5554,\n",
      "         0.5139, 0.3857, 0.5406],\n",
      "        [0.6539, 0.4646, 0.4091, 0.4697, 0.6051, 0.4109, 0.5128, 0.5356, 0.3762,\n",
      "         0.5932, 0.4694, 0.4836, 0.3899, 0.4034, 0.2760, 0.4864, 0.4953, 0.4250,\n",
      "         0.4945, 0.7140, 0.3068, 0.4972, 0.3208, 0.4968, 0.4812, 0.2405, 0.4678,\n",
      "         0.3244, 0.6272, 0.3940],\n",
      "        [0.4925, 0.4491, 0.4633, 0.5021, 0.3776, 0.4631, 0.4744, 0.4261, 0.5007,\n",
      "         0.5161, 0.3774, 0.4148, 0.5441, 0.5127, 0.4158, 0.5300, 0.6625, 0.6444,\n",
      "         0.4504, 0.4493, 0.3585, 0.4789, 0.6570, 0.5600, 0.4760, 0.6189, 0.5809,\n",
      "         0.5443, 0.5278, 0.4930],\n",
      "        [0.2925, 0.4763, 0.4223, 0.4513, 0.4165, 0.4762, 0.5304, 0.2868, 0.3766,\n",
      "         0.4940, 0.5264, 0.5328, 0.5661, 0.2964, 0.4956, 0.4283, 0.5569, 0.4825,\n",
      "         0.3698, 0.4656, 0.4660, 0.4710, 0.6055, 0.4725, 0.6726, 0.5275, 0.4934,\n",
      "         0.5644, 0.3743, 0.5277],\n",
      "        [0.5822, 0.6217, 0.4818, 0.5431, 0.5073, 0.4008, 0.5064, 0.4942, 0.5352,\n",
      "         0.3902, 0.4442, 0.6013, 0.4762, 0.3176, 0.5616, 0.4498, 0.2670, 0.4276,\n",
      "         0.5879, 0.5211, 0.3796, 0.5656, 0.4373, 0.5163, 0.4917, 0.5135, 0.5200,\n",
      "         0.5893, 0.4732, 0.4390],\n",
      "        [0.4512, 0.5238, 0.4095, 0.2713, 0.6950, 0.3892, 0.4528, 0.4906, 0.5440,\n",
      "         0.7097, 0.5029, 0.4471, 0.4982, 0.5567, 0.5052, 0.4243, 0.4133, 0.4710,\n",
      "         0.4385, 0.5095, 0.3740, 0.5879, 0.4700, 0.4138, 0.4109, 0.4564, 0.5044,\n",
      "         0.4372, 0.3156, 0.4698],\n",
      "        [0.4767, 0.4057, 0.4517, 0.4360, 0.5825, 0.5823, 0.4446, 0.4050, 0.6097,\n",
      "         0.5536, 0.4566, 0.4924, 0.3552, 0.3702, 0.4174, 0.5362, 0.3667, 0.5594,\n",
      "         0.4964, 0.5745, 0.5466, 0.5069, 0.4592, 0.4582, 0.4847, 0.5201, 0.4152,\n",
      "         0.5318, 0.6107, 0.4540],\n",
      "        [0.3430, 0.4295, 0.4794, 0.4443, 0.4231, 0.5230, 0.5960, 0.3106, 0.3770,\n",
      "         0.5063, 0.5312, 0.4572, 0.5664, 0.4795, 0.6284, 0.5923, 0.4923, 0.4446,\n",
      "         0.6216, 0.4208, 0.4606, 0.4762, 0.5964, 0.5577, 0.5002, 0.5383, 0.5661,\n",
      "         0.6448, 0.4271, 0.4769],\n",
      "        [0.2746, 0.4947, 0.3734, 0.3463, 0.5258, 0.4730, 0.4791, 0.3899, 0.3654,\n",
      "         0.4139, 0.5453, 0.4453, 0.4040, 0.5802, 0.5612, 0.7066, 0.4414, 0.4922,\n",
      "         0.4442, 0.5202, 0.5411, 0.4702, 0.4277, 0.3147, 0.3396, 0.4101, 0.5632,\n",
      "         0.3345, 0.4414, 0.4575],\n",
      "        [0.4633, 0.3806, 0.5634, 0.3263, 0.5486, 0.5350, 0.5121, 0.6577, 0.5281,\n",
      "         0.5426, 0.5625, 0.4995, 0.6215, 0.4270, 0.3315, 0.5814, 0.6419, 0.3937,\n",
      "         0.6592, 0.5377, 0.4612, 0.4982, 0.4895, 0.4547, 0.6653, 0.5973, 0.3888,\n",
      "         0.3270, 0.4133, 0.4160],\n",
      "        [0.6911, 0.4464, 0.5438, 0.4204, 0.4666, 0.4232, 0.4257, 0.3207, 0.5352,\n",
      "         0.4615, 0.5463, 0.4188, 0.5878, 0.4841, 0.4754, 0.4143, 0.3067, 0.7135,\n",
      "         0.3469, 0.5953, 0.4971, 0.3403, 0.4254, 0.5470, 0.2807, 0.2924, 0.3627,\n",
      "         0.3390, 0.6114, 0.3529],\n",
      "        [0.6269, 0.4757, 0.5947, 0.4240, 0.3497, 0.4618, 0.4726, 0.6469, 0.5029,\n",
      "         0.5633, 0.3066, 0.4088, 0.4922, 0.6956, 0.5156, 0.6745, 0.4570, 0.5032,\n",
      "         0.4806, 0.5825, 0.4515, 0.5020, 0.5477, 0.6843, 0.4971, 0.5002, 0.5320,\n",
      "         0.4703, 0.4384, 0.3281],\n",
      "        [0.5116, 0.4588, 0.4690, 0.3518, 0.3227, 0.4329, 0.6019, 0.5541, 0.7041,\n",
      "         0.6233, 0.3612, 0.6519, 0.4267, 0.4019, 0.3180, 0.5396, 0.4900, 0.5614,\n",
      "         0.4475, 0.5198, 0.6909, 0.4822, 0.4294, 0.4439, 0.4293, 0.4693, 0.4675,\n",
      "         0.4040, 0.5421, 0.4255]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((5, 3, 256, 256))\n",
    "model = Discriminator(in_channels = 3)\n",
    "preds = model(x)\n",
    "print(preds.shape)\n",
    "print(preds[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, down = True, use_act = True, **kwargs):\n",
    "    super(ConvBlock, self).__init__()\n",
    "    self.conv = nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, padding_mode = 'reflect', **kwargs)\n",
    "        if down else \n",
    "        nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n",
    "        nn.InstanceNorm2d(out_channels),\n",
    "        nn.ReLU(inplace = True) if use_act else nn.Identity()\n",
    "    )\n",
    "  def forward(self, x):\n",
    "    return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "  def __init__(self, channels):\n",
    "    super(ResidualBlock, self).__init__()\n",
    "    self.block = nn.Sequential(\n",
    "      ConvBlock(channels, channels, kernel_size = 3, padding = 1),\n",
    "      ConvBlock(channels, channels, use_act = False, kernel_size = 3, padding = 1)\n",
    "  )\n",
    "  def forward(self, x):\n",
    "    return x + self.block(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 생성기 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "  def __init__(self, img_channels,num_features = 64, num_resblock = 9):\n",
    "    super(Generator, self).__init__()\n",
    "    self.initial = nn.Sequential(\n",
    "        nn.Conv2d(img_channels, num_features, kernel_size = 7, stride = 1, padding = 3, padding_mode = 'reflect'),\n",
    "        nn.ReLU(inplace = True)\n",
    "    )\n",
    "    self.down_blocks = nn.ModuleList(\n",
    "      [\n",
    "          ConvBlock(num_features, num_features * 2, kernel_size = 3, stride = 2, padding = 1),\n",
    "       ConvBlock(num_features * 2, num_features * 4, kernel_size = 3, stride = 2, padding = 1),]\n",
    "    )\n",
    "    self.residual_block = nn.Sequential(\n",
    "        *[ResidualBlock(num_features * 4) for _ in range(num_resblock)]\n",
    "    )\n",
    "\n",
    "    self.up_blocks = nn.ModuleList(\n",
    "        [\n",
    "        ConvBlock(num_features * 4, num_features * 2, down = False, kernel_size = 3, stride = 2,padding = 1, output_padding = 1),\n",
    "        ConvBlock(num_features * 2, num_features, down = False, kernel_size = 3, stride = 2,padding = 1, output_padding = 1)\n",
    "    ])\n",
    "    \n",
    "    self.last = nn.Conv2d(num_features * 1, img_channels, kernel_size = 7, stride = 1, padding = 3, padding_mode = 'reflect')\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.initial(x)\n",
    "    for layer in self.down_blocks:\n",
    "      x = layer(x)\n",
    "    x= self.residual_block(x)\n",
    "    for layer in self.up_blocks:\n",
    "      x = layer(x)\n",
    "    \n",
    "    return torch.tanh(self.last(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "test = torch.randn(2, 3, 256, 256)\n",
    "gen = Generator(3)\n",
    "print(gen(test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_ = [transforms.Resize(256),\n",
    "                                  transforms.RandomHorizontalFlip(),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "test_trans = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋은 celeb attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Dataset(Dataset):\n",
    "  def __init__(self, root, transforms_ = None, mode = 'train'):\n",
    "    self.transforms = transforms.Compose(transforms_)\n",
    "    \n",
    "    self.file_A = sorted(glob.glob(os.path.join(root, 'trainA') + '/*')) \n",
    "    self.file_B = sorted(glob.glob(os.path.join(root, 'trainB') + '/*'))\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    itemA = self.transforms(Image.open(self.file_A[index % len(self.file_A)]))\n",
    "\n",
    "    itemB = self.transforms(Image.open(self.file_B[index % len(self.file_B)]))\n",
    "\n",
    "    return {'A' : itemA, 'B' : itemB}\n",
    "\n",
    "  def __len__(self):\n",
    "    return max(len(self.file_A), len(self.file_B))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#root= \"C:\\\\Users\\\\User\\\\Desktop\\\\GAN proj\\\\archive\\\\img_align_celeba\\\\img_align_celeba_AB\\\\\"\n",
    "root = \"D:\\\\다운로드\\\\archive\\\\dataAB\\\\\"\n",
    "batch_size = 32\n",
    "learning_rate = 2e-4\n",
    "lambda_identity = 0\n",
    "lambda_cycle = 10\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_H = Discriminator(in_channels = 3).to(device)\n",
    "disc_Z = Discriminator(in_channels = 3).to(device)\n",
    "gen_Z = Generator(img_channels = 3, num_resblock = 9).to(device)\n",
    "gen_H = Generator(img_channels = 3, num_resblock = 9).to(device)\n",
    "\n",
    "optim_disc = optim.Adam(list(disc_H.parameters()) + list(disc_Z.parameters()),\n",
    "                        lr = learning_rate, betas = (0.5, 0.999))\n",
    "optim_gen = optim.Adam(list(gen_Z.parameters()) + list(gen_H.parameters()),\n",
    "                       lr = learning_rate, betas = (0.5, 0.999))\n",
    "L1 = nn.L1Loss()\n",
    "mse = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Custom_Dataset(\n",
    "     root, transforms_ = transforms_\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size = 2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagea = next(iter(dataloader))['A'][0]\n",
    "imageb = next(iter(dataloader))['B'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b8ce9f3490>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(torchvision.utils.make_grid(imagea, normalize = True).permute(1, 2, 0)) #a 안경 X\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(torchvision.utils.make_grid(imageb, normalize = True).permute(1, 2, 0)) #b 안경 O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imagea.size())\n",
    "print(imageb.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gen_A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m optim_disc\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m      7\u001b[0m optim_gen\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m----> 9\u001b[0m fake_apple \u001b[39m=\u001b[39m gen_A(orange) \n\u001b[0;32m     10\u001b[0m D_A_real \u001b[39m=\u001b[39m disc_A(horse) \n\u001b[0;32m     11\u001b[0m D_A_fake \u001b[39m=\u001b[39m disc_A(fake_horse\u001b[39m.\u001b[39mdetach()) \n",
      "\u001b[1;31mNameError\u001b[0m: name 'gen_A' is not defined"
     ]
    }
   ],
   "source": [
    "# disc_H = Discriminator(in_channels = 3).to(device) = disc_A\n",
    "# disc_Z = Discriminator(in_channels = 3).to(device) = disc_O\n",
    "# gen_Z = Generator(img_channels = 3, num_resblock = 9).to(device) = gen_O\n",
    "# gen_H = Generator(img_channels = 3, num_resblock = 9).to(device) = gen_A\n",
    "# zebra = orange, horse = apple\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  for idx, batch in enumerate(dataloader):\n",
    "  \n",
    "    orange = batch['B'].to(device)\n",
    "    apple = batch['A'].to(device)\n",
    "    optim_disc.zero_grad()\n",
    "    optim_gen.zero_grad()\n",
    "\n",
    "    fake_apple = gen_H(orange) \n",
    "    D_A_real = disc_H(apple) \n",
    "    D_A_fake = disc_H(fake_apple.detach()) \n",
    "    D_A_real_loss = mse(D_A_real, torch.ones_like(D_A_real))\n",
    "    D_A_fake_loss = mse(D_A_fake, torch.zeros_like(D_A_fake)) \n",
    "    D_A_loss = D_A_real_loss + D_A_fake_loss \n",
    "\n",
    "    fake_orange = gen_Z(apple)\n",
    "    D_O_real = disc_Z(orange)\n",
    "    D_O_fake = disc_Z(fake_orange.detach())\n",
    "    D_O_real_loss = mse(D_O_real, torch.ones_like(D_O_real))\n",
    "    D_O_fake_loss = mse(D_O_fake, torch.zeros_like(D_O_fake))\n",
    "    D_O_loss = D_O_real_loss + D_O_fake_loss\n",
    "\n",
    "    D_loss = (D_A_loss + D_O_loss) / 2\n",
    "\n",
    "    D_loss.backward()\n",
    "    optim_disc.step()\n",
    "    #generator 학습\n",
    "    D_A_fake = disc_H(fake_apple)\n",
    "    D_O_fake = disc_Z(fake_orange)\n",
    "    loss_G_A = mse(D_O_fake, torch.ones_like(D_A_fake)) #CE 를 쓰지않고 여기서 정의된 새로운 손실함수 \n",
    "    loss_G_O = mse(D_O_fake, torch.ones_like(D_O_fake))\n",
    "\n",
    "    cycle_orange = gen_Z(fake_apple)\n",
    "    cycle_apple = gen_H(fake_orange)\n",
    "    cycle_orange_loss = L1(orange, cycle_orange)\n",
    "    cycle_apple_loss = L1(apple, cycle_apple)\n",
    "\n",
    "    identity_orange = gen_Z(orange)\n",
    "    identity_apple = gen_H(apple)\n",
    "    identity_orange_loss = L1(orange, identity_orange)\n",
    "    identity_apple_loss = L1(apple, identity_apple)\n",
    "\n",
    "    G_loss = (loss_G_O + loss_G_A + cycle_orange_loss * lambda_cycle + cycle_apple_loss * lambda_cycle\n",
    "              +identity_apple_loss * lambda_identity + identity_orange_loss * lambda_identity)\n",
    "    G_loss.backward()\n",
    "    optim_gen.step()\n",
    "    if idx == 50:\n",
    "      print('EPOCH : ', epoch, 'G_loss : ', G_loss, 'D_loss :', D_loss)\n",
    "      break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gen_H, 'gen_H.pt')\n",
    "torch.save(gen_Z, 'gen_Z.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_image = iter(dataloader).next()['A'][1]\n",
    "orange_image = iter(dataloader).next()['B'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_image = apple_image.to(device)\n",
    "orange_image = orange_image.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델에 이미지 넣어서 결과 확인.\n",
    "나름 잘 변환된 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(torchvision.utils.make_grid(apple_image.cpu(), normalize = True).permute(1, 2, 0)) \n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(torchvision.utils.make_grid(orange_image.cpu(), normalize = True).permute(1, 2, 0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_apple = gen_H(orange_image).cpu()\n",
    "plt.imshow(torchvision.utils.make_grid(trans_apple.cpu(), normalize = True).permute(1, 2, 0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_orange = gen_Z(apple_image).cpu()\n",
    "plt.imshow(torchvision.utils.make_grid(trans_orange.cpu(), normalize = True).permute(1, 2, 0)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "celeb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54b35b3adbbd70330d6102a494230c62f4578d0a77ac8239ed45d9ee8bea0e04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

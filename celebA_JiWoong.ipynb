{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, stride):\n",
    "    super(Block, self).__init__()\n",
    "    self.conv = nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 4, stride, 1, bias = True, padding_mode = 'reflect'),\n",
    "        nn.InstanceNorm2d(out_channels),\n",
    "        nn.LeakyReLU(0.2)\n",
    "    )\n",
    "  def forward(self, x):\n",
    "    return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "  def __init__(self, in_channels = 3, features = [64, 128, 256, 512]):\n",
    "    super(Discriminator, self).__init__()\n",
    "    self.initial = nn.Sequential(\n",
    "        nn.Conv2d(in_channels, features[0], kernel_size = 4, stride = 2, padding = 1, padding_mode ='reflect'), # Conv(3, 64, 4, 2, 1)\n",
    "    nn.LeakyReLU(0.2))\n",
    "\n",
    "    layers = []\n",
    "    in_channels = features[0]\n",
    "    for feature in features[1:]:\n",
    "      layers.append(Block(in_channels, feature, stride = 1 if feature == features[-1] else 2)) #Conv(64,128, 4, 2, 1),Conv(128,256, 4, 2, 1), Conv(256, 512, 4, 1, 1)  담는다\n",
    "      in_channels = feature # \n",
    "    layers.append(nn.Conv2d(in_channels,1, kernel_size = 4, stride = 1, padding = 1, padding_mode = 'reflect')) #Conv(512, 1, 4, 1, 1)\n",
    "    self.model = nn.Sequential(*layers)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.initial(x)\n",
    "    return torch.sigmoid(self.model(x)) # 30 x 30 pathgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 30, 30])\n",
      "tensor([[0.4113, 0.4587, 0.4163, 0.4391, 0.6051, 0.5079, 0.5611, 0.5580, 0.4942,\n",
      "         0.6981, 0.5104, 0.5746, 0.5548, 0.4938, 0.5249, 0.6007, 0.4994, 0.4636,\n",
      "         0.4318, 0.4282, 0.3624, 0.6442, 0.3529, 0.5489, 0.4001, 0.5435, 0.6228,\n",
      "         0.5020, 0.5933, 0.6306],\n",
      "        [0.3973, 0.4109, 0.3886, 0.5116, 0.5029, 0.4999, 0.5075, 0.4824, 0.5399,\n",
      "         0.6415, 0.4624, 0.5046, 0.5449, 0.4509, 0.4660, 0.4153, 0.5132, 0.4364,\n",
      "         0.5948, 0.5069, 0.6183, 0.5333, 0.5324, 0.4331, 0.4943, 0.5394, 0.6449,\n",
      "         0.4844, 0.3895, 0.3988],\n",
      "        [0.5007, 0.4647, 0.5275, 0.4052, 0.5639, 0.6084, 0.4784, 0.4081, 0.5694,\n",
      "         0.5129, 0.4519, 0.5260, 0.6085, 0.5103, 0.5274, 0.5918, 0.5410, 0.4534,\n",
      "         0.4250, 0.4800, 0.3410, 0.5600, 0.6295, 0.4776, 0.4027, 0.4346, 0.4218,\n",
      "         0.5083, 0.4780, 0.4761],\n",
      "        [0.5143, 0.5899, 0.5050, 0.6209, 0.6902, 0.5357, 0.4176, 0.5458, 0.6463,\n",
      "         0.5483, 0.5866, 0.4518, 0.5221, 0.5895, 0.6524, 0.5354, 0.4118, 0.6044,\n",
      "         0.5854, 0.6461, 0.5161, 0.4546, 0.4340, 0.5366, 0.5782, 0.5335, 0.4384,\n",
      "         0.4585, 0.5288, 0.3232],\n",
      "        [0.4874, 0.5730, 0.4311, 0.5071, 0.5261, 0.4623, 0.5635, 0.3909, 0.4506,\n",
      "         0.4473, 0.5353, 0.5938, 0.4328, 0.4033, 0.5359, 0.4847, 0.5812, 0.4884,\n",
      "         0.5490, 0.4780, 0.5177, 0.3370, 0.5371, 0.4419, 0.5691, 0.5668, 0.5568,\n",
      "         0.6030, 0.5260, 0.5640],\n",
      "        [0.5147, 0.4581, 0.5808, 0.5067, 0.4315, 0.4568, 0.5312, 0.4082, 0.6030,\n",
      "         0.5638, 0.3589, 0.4118, 0.5996, 0.4434, 0.4341, 0.5213, 0.7028, 0.4908,\n",
      "         0.5569, 0.5785, 0.4980, 0.7143, 0.4881, 0.4870, 0.6177, 0.3738, 0.3976,\n",
      "         0.3722, 0.5136, 0.5259],\n",
      "        [0.4593, 0.4311, 0.5486, 0.4896, 0.5044, 0.4416, 0.4034, 0.6341, 0.3754,\n",
      "         0.5252, 0.5321, 0.6387, 0.3094, 0.3961, 0.4825, 0.4124, 0.4600, 0.4872,\n",
      "         0.5020, 0.5194, 0.4352, 0.5764, 0.5487, 0.5267, 0.6828, 0.6382, 0.7679,\n",
      "         0.3985, 0.6123, 0.3412],\n",
      "        [0.4316, 0.6366, 0.4654, 0.4252, 0.6126, 0.5815, 0.5155, 0.6269, 0.5298,\n",
      "         0.5466, 0.3967, 0.3958, 0.5687, 0.5135, 0.4505, 0.5353, 0.4324, 0.5285,\n",
      "         0.4716, 0.4239, 0.5275, 0.5549, 0.3773, 0.6252, 0.6744, 0.4281, 0.3831,\n",
      "         0.6328, 0.6227, 0.6615],\n",
      "        [0.4251, 0.4899, 0.4808, 0.5312, 0.3442, 0.4292, 0.5948, 0.5632, 0.4203,\n",
      "         0.4026, 0.4861, 0.5202, 0.4974, 0.5134, 0.4335, 0.4888, 0.4346, 0.5785,\n",
      "         0.4648, 0.5137, 0.6002, 0.4868, 0.6014, 0.4943, 0.5530, 0.4444, 0.5164,\n",
      "         0.5301, 0.3969, 0.5934],\n",
      "        [0.7144, 0.6203, 0.6107, 0.3709, 0.5158, 0.5055, 0.4983, 0.5549, 0.3607,\n",
      "         0.4001, 0.4587, 0.5231, 0.5928, 0.4257, 0.5301, 0.4994, 0.6366, 0.5165,\n",
      "         0.5416, 0.5100, 0.5484, 0.4153, 0.4893, 0.5367, 0.5873, 0.4883, 0.5635,\n",
      "         0.5058, 0.3962, 0.6015],\n",
      "        [0.6008, 0.5810, 0.5151, 0.5310, 0.6853, 0.4606, 0.5067, 0.5737, 0.4012,\n",
      "         0.6070, 0.5882, 0.6429, 0.4758, 0.4085, 0.6481, 0.6139, 0.3840, 0.5513,\n",
      "         0.6162, 0.5002, 0.6646, 0.5035, 0.6861, 0.4479, 0.3110, 0.5707, 0.4475,\n",
      "         0.6319, 0.4855, 0.6627],\n",
      "        [0.3796, 0.4851, 0.4559, 0.6218, 0.6066, 0.5633, 0.6024, 0.4140, 0.4361,\n",
      "         0.3613, 0.4799, 0.4755, 0.4275, 0.4197, 0.4117, 0.5904, 0.4735, 0.5368,\n",
      "         0.4999, 0.4983, 0.4340, 0.4832, 0.6573, 0.6145, 0.6935, 0.4837, 0.5960,\n",
      "         0.3528, 0.5105, 0.2847],\n",
      "        [0.5399, 0.5149, 0.4093, 0.5677, 0.3623, 0.4003, 0.3933, 0.4606, 0.6594,\n",
      "         0.4973, 0.5247, 0.5031, 0.6682, 0.4847, 0.5195, 0.4637, 0.3487, 0.2921,\n",
      "         0.6073, 0.5409, 0.5522, 0.2853, 0.5858, 0.6579, 0.5177, 0.4856, 0.4624,\n",
      "         0.5824, 0.4639, 0.5388],\n",
      "        [0.4333, 0.6853, 0.4468, 0.3716, 0.5440, 0.3259, 0.5139, 0.4493, 0.5312,\n",
      "         0.4609, 0.4530, 0.6061, 0.6375, 0.5725, 0.4841, 0.4500, 0.6002, 0.4973,\n",
      "         0.5185, 0.5235, 0.4679, 0.3335, 0.5270, 0.4545, 0.5522, 0.5724, 0.7128,\n",
      "         0.5978, 0.5081, 0.5757],\n",
      "        [0.6057, 0.6353, 0.6903, 0.5588, 0.5406, 0.4057, 0.3403, 0.6189, 0.3425,\n",
      "         0.4228, 0.5336, 0.4235, 0.4616, 0.4804, 0.4822, 0.5690, 0.5284, 0.4785,\n",
      "         0.4577, 0.3749, 0.4726, 0.6325, 0.5025, 0.5536, 0.5381, 0.5134, 0.4809,\n",
      "         0.5711, 0.3990, 0.4381],\n",
      "        [0.5756, 0.5361, 0.3657, 0.4417, 0.6056, 0.4599, 0.4759, 0.3863, 0.5775,\n",
      "         0.6480, 0.5396, 0.4751, 0.5157, 0.4362, 0.4914, 0.5053, 0.3916, 0.4072,\n",
      "         0.6003, 0.3909, 0.6802, 0.5609, 0.4974, 0.4919, 0.5698, 0.4649, 0.5988,\n",
      "         0.5859, 0.5205, 0.6257],\n",
      "        [0.4190, 0.6032, 0.3930, 0.5571, 0.5405, 0.4205, 0.5481, 0.5444, 0.5029,\n",
      "         0.5721, 0.5718, 0.5451, 0.6550, 0.4929, 0.4796, 0.5113, 0.5831, 0.6338,\n",
      "         0.4512, 0.6157, 0.3791, 0.5099, 0.3426, 0.5338, 0.5867, 0.5376, 0.6658,\n",
      "         0.5781, 0.3876, 0.3856],\n",
      "        [0.4237, 0.4815, 0.5623, 0.4688, 0.5253, 0.4578, 0.4357, 0.3545, 0.6558,\n",
      "         0.3944, 0.5717, 0.4194, 0.6514, 0.5508, 0.3462, 0.6340, 0.6823, 0.4895,\n",
      "         0.5423, 0.4336, 0.7265, 0.6863, 0.4774, 0.4246, 0.5375, 0.3790, 0.7453,\n",
      "         0.5803, 0.6610, 0.4677],\n",
      "        [0.5130, 0.4426, 0.4684, 0.5454, 0.4985, 0.4717, 0.5775, 0.4024, 0.5605,\n",
      "         0.4722, 0.4261, 0.5823, 0.5029, 0.4384, 0.4140, 0.4882, 0.3505, 0.5853,\n",
      "         0.4903, 0.3894, 0.4375, 0.4640, 0.3300, 0.3989, 0.4834, 0.5214, 0.5990,\n",
      "         0.4183, 0.5555, 0.3731],\n",
      "        [0.6069, 0.4455, 0.6137, 0.5866, 0.5188, 0.4280, 0.5324, 0.4308, 0.4995,\n",
      "         0.4532, 0.4675, 0.5962, 0.4773, 0.4843, 0.4925, 0.6248, 0.7175, 0.3487,\n",
      "         0.4912, 0.4808, 0.4845, 0.3682, 0.4586, 0.4493, 0.4584, 0.3509, 0.4527,\n",
      "         0.5922, 0.3523, 0.5936],\n",
      "        [0.4856, 0.6900, 0.4206, 0.4324, 0.6000, 0.6637, 0.4031, 0.3279, 0.4505,\n",
      "         0.5059, 0.5601, 0.4977, 0.4914, 0.6872, 0.5601, 0.5157, 0.4226, 0.5543,\n",
      "         0.5363, 0.5101, 0.4586, 0.7020, 0.5465, 0.5391, 0.4014, 0.4755, 0.5694,\n",
      "         0.5789, 0.5077, 0.5049],\n",
      "        [0.4299, 0.4965, 0.6246, 0.5414, 0.4947, 0.5547, 0.4751, 0.3978, 0.5098,\n",
      "         0.4245, 0.3780, 0.6593, 0.5203, 0.4801, 0.4788, 0.5804, 0.6500, 0.5173,\n",
      "         0.4961, 0.5994, 0.6029, 0.4814, 0.5161, 0.6997, 0.3134, 0.6691, 0.6399,\n",
      "         0.6417, 0.6019, 0.6703],\n",
      "        [0.3441, 0.5289, 0.6848, 0.5070, 0.5089, 0.6572, 0.4382, 0.4181, 0.4092,\n",
      "         0.5461, 0.5713, 0.4881, 0.5621, 0.4185, 0.5420, 0.5459, 0.6594, 0.5878,\n",
      "         0.3275, 0.3860, 0.4697, 0.5818, 0.4884, 0.5617, 0.4116, 0.4613, 0.5719,\n",
      "         0.5118, 0.5317, 0.5504],\n",
      "        [0.4078, 0.5553, 0.4457, 0.4935, 0.5834, 0.6175, 0.5706, 0.3819, 0.6227,\n",
      "         0.4620, 0.5347, 0.4416, 0.5090, 0.4948, 0.5970, 0.5620, 0.4198, 0.5543,\n",
      "         0.4681, 0.7276, 0.6355, 0.6464, 0.5767, 0.5279, 0.5686, 0.6048, 0.3131,\n",
      "         0.5812, 0.4720, 0.4970],\n",
      "        [0.5421, 0.5701, 0.3161, 0.4384, 0.5466, 0.5809, 0.5183, 0.5277, 0.5579,\n",
      "         0.5238, 0.6646, 0.3873, 0.4019, 0.5183, 0.4165, 0.5541, 0.5409, 0.6049,\n",
      "         0.4469, 0.5729, 0.4659, 0.4816, 0.4169, 0.4998, 0.6328, 0.5485, 0.4654,\n",
      "         0.6462, 0.5723, 0.6649],\n",
      "        [0.3172, 0.3879, 0.5407, 0.3706, 0.4446, 0.3617, 0.5834, 0.5198, 0.3043,\n",
      "         0.5031, 0.4538, 0.5127, 0.5299, 0.5008, 0.5281, 0.5133, 0.4793, 0.5334,\n",
      "         0.6920, 0.5822, 0.4521, 0.6543, 0.5510, 0.4045, 0.5921, 0.4262, 0.6925,\n",
      "         0.5505, 0.5381, 0.5198],\n",
      "        [0.4904, 0.6630, 0.5859, 0.3320, 0.5786, 0.5759, 0.5247, 0.5864, 0.5104,\n",
      "         0.5131, 0.3431, 0.5813, 0.5464, 0.5349, 0.3911, 0.4121, 0.4947, 0.4402,\n",
      "         0.4966, 0.3954, 0.6039, 0.4334, 0.6298, 0.6152, 0.3774, 0.3644, 0.6396,\n",
      "         0.4868, 0.4878, 0.5796],\n",
      "        [0.4331, 0.4951, 0.5564, 0.3449, 0.4264, 0.3560, 0.4486, 0.5350, 0.5954,\n",
      "         0.4761, 0.3658, 0.6266, 0.4826, 0.6201, 0.5621, 0.5714, 0.3516, 0.6180,\n",
      "         0.5323, 0.4848, 0.5383, 0.4094, 0.5377, 0.4518, 0.4194, 0.5664, 0.4823,\n",
      "         0.6039, 0.5796, 0.3987],\n",
      "        [0.3435, 0.5989, 0.4706, 0.3517, 0.4647, 0.3294, 0.7220, 0.4931, 0.3267,\n",
      "         0.5298, 0.5271, 0.4709, 0.4906, 0.3496, 0.5219, 0.4892, 0.6232, 0.4377,\n",
      "         0.4836, 0.5164, 0.5625, 0.4188, 0.4476, 0.5546, 0.6658, 0.4467, 0.5198,\n",
      "         0.5966, 0.4834, 0.4564],\n",
      "        [0.4902, 0.5671, 0.5961, 0.4419, 0.4520, 0.4119, 0.5514, 0.5169, 0.6337,\n",
      "         0.3321, 0.5512, 0.5897, 0.5875, 0.4625, 0.5035, 0.5348, 0.5610, 0.4807,\n",
      "         0.7098, 0.3397, 0.6271, 0.4584, 0.5818, 0.4479, 0.5320, 0.5223, 0.4187,\n",
      "         0.5695, 0.4024, 0.4472]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((5, 3, 256, 256))\n",
    "model = Discriminator(in_channels = 3)\n",
    "preds = model(x)\n",
    "print(preds.shape)\n",
    "print(preds[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, down = True, use_act = True, **kwargs):\n",
    "    super(ConvBlock, self).__init__()\n",
    "    self.conv = nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, padding_mode = 'reflect', **kwargs)\n",
    "        if down else \n",
    "        nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n",
    "        nn.InstanceNorm2d(out_channels),\n",
    "        nn.ReLU(inplace = True) if use_act else nn.Identity()\n",
    "    )\n",
    "  def forward(self, x):\n",
    "    return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "  def __init__(self, channels):\n",
    "    super(ResidualBlock, self).__init__()\n",
    "    self.block = nn.Sequential(\n",
    "      ConvBlock(channels, channels, kernel_size = 3, padding = 1),\n",
    "      ConvBlock(channels, channels, use_act = False, kernel_size = 3, padding = 1)\n",
    "  )\n",
    "  def forward(self, x):\n",
    "    return x + self.block(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 생성기 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "  def __init__(self, img_channels,num_features = 64, num_resblock = 9):\n",
    "    super(Generator, self).__init__()\n",
    "    self.initial = nn.Sequential(\n",
    "        nn.Conv2d(img_channels, num_features, kernel_size = 7, stride = 1, padding = 3, padding_mode = 'reflect'),\n",
    "        nn.ReLU(inplace = True)\n",
    "    )\n",
    "    self.down_blocks = nn.ModuleList(\n",
    "      [\n",
    "          ConvBlock(num_features, num_features * 2, kernel_size = 3, stride = 2, padding = 1),\n",
    "       ConvBlock(num_features * 2, num_features * 4, kernel_size = 3, stride = 2, padding = 1),]\n",
    "    )\n",
    "    self.residual_block = nn.Sequential(\n",
    "        *[ResidualBlock(num_features * 4) for _ in range(num_resblock)]\n",
    "    )\n",
    "\n",
    "    self.up_blocks = nn.ModuleList(\n",
    "        [\n",
    "        ConvBlock(num_features * 4, num_features * 2, down = False, kernel_size = 3, stride = 2,padding = 1, output_padding = 1),\n",
    "        ConvBlock(num_features * 2, num_features, down = False, kernel_size = 3, stride = 2,padding = 1, output_padding = 1)\n",
    "    ])\n",
    "    \n",
    "    self.last = nn.Conv2d(num_features * 1, img_channels, kernel_size = 7, stride = 1, padding = 3, padding_mode = 'reflect')\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.initial(x)\n",
    "    for layer in self.down_blocks:\n",
    "      x = layer(x)\n",
    "    x= self.residual_block(x)\n",
    "    for layer in self.up_blocks:\n",
    "      x = layer(x)\n",
    "    \n",
    "    return torch.tanh(self.last(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "test = torch.randn(2, 3, 256, 256)\n",
    "gen = Generator(3)\n",
    "print(gen(test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_ = [transforms.Resize(256),\n",
    "                                  transforms.RandomHorizontalFlip(),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "test_trans = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋은 celeb attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Dataset(Dataset):\n",
    "  def __init__(self, root, transforms_ = None, mode = 'train'):\n",
    "    self.transforms = transforms.Compose(transforms_)\n",
    "    \n",
    "    self.file_A = sorted(glob.glob(os.path.join(root, 'trainA') + '/*')) \n",
    "    self.file_B = sorted(glob.glob(os.path.join(root, 'trainB') + '/*'))\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    itemA = self.transforms(Image.open(self.file_A[index % len(self.file_A)]))\n",
    "\n",
    "    itemB = self.transforms(Image.open(self.file_B[index % len(self.file_B)]))\n",
    "\n",
    "    return {'A' : itemA, 'B' : itemB}\n",
    "\n",
    "  def __len__(self):\n",
    "    return max(len(self.file_A), len(self.file_B))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root= '/content/drive/MyDrive/apple2orange/apple2orange'\n",
    "batch_size = 32\n",
    "learning_rate = 2e-4\n",
    "lambda_identity = 0\n",
    "lambda_cycle = 10\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_H = Discriminator(in_channels = 3).to(device)\n",
    "disc_Z = Discriminator(in_channels = 3).to(device)\n",
    "gen_Z = Generator(img_channels = 3, num_resblock = 9).to(device)\n",
    "gen_H = Generator(img_channels = 3, num_resblock = 9).to(device)\n",
    "\n",
    "optim_disc = optim.Adam(list(disc_H.parameters()) + list(disc_Z.parameters()),\n",
    "                        lr = learning_rate, betas = (0.5, 0.999))\n",
    "optim_gen = optim.Adam(list(gen_Z.parameters()) + list(gen_H.parameters()),\n",
    "                       lr = learning_rate, betas = (0.5, 0.999))\n",
    "L1 = nn.L1Loss()\n",
    "mse = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Custom_Dataset(\n",
    "     root, transforms_ = transforms_\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size = 2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagea = iter(dataloader).next()['A'][1]\n",
    "imageb = iter(dataloader).next()['B'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(torchvision.utils.make_grid(imagea, normalize = True).permute(1, 2, 0)) #a에는 사과\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(torchvision.utils.make_grid(imageb, normalize = True).permute(1, 2, 0)) #b은 오렌지가 들어있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imagea.size())\n",
    "print(imageb.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "  for idx, batch in enumerate(dataloader):\n",
    "  \n",
    "    orange = batch['B'].to(device)\n",
    "    apple = batch['A'].to(device)\n",
    "    optim_disc.zero_grad()\n",
    "    optim_gen.zero_grad()\n",
    "\n",
    "    fake_apple = gen_A(orange) \n",
    "    D_A_real = disc_A(horse) \n",
    "    D_A_fake = disc_A(fake_horse.detach()) \n",
    "    D_A_real_loss = mse(D_A_real, torch.ones_like(D_A_real))\n",
    "    D_A_fake_loss = mse(D_A_fake, torch.zeros_like(D_A_fake)) \n",
    "    D_A_loss = D_A_real_loss + D_A_fake_loss \n",
    "\n",
    "    fake_orange = gen_O(apple)\n",
    "    D_O_real = disc_Z(zebra)\n",
    "    D_O_fake = disc_Z(fake_zebra.detach())\n",
    "    D_O_real_loss = mse(D_O_real, torch.ones_like(D_O_real))\n",
    "    D_O_fake_loss = mse(D_O_fake, torch.zeros_like(D_O_fake))\n",
    "    D_O_loss = D_O_real_loss + D_O_fake_loss\n",
    "\n",
    "    D_loss = (D_A_loss + D_O_loss) / 2\n",
    "\n",
    "    D_loss.backward()\n",
    "    optim_disc.step()\n",
    "    #generator 학습\n",
    "    D_A_fake = disc_A(fake_apple)\n",
    "    D_O_fake = disc_O(fake_orange)\n",
    "    loss_G_A = mse(D_Z_fake, torch.ones_like(D_A_fake)) #CE 를 쓰지않고 여기서 정의된 새로운 손실함수 \n",
    "    loss_G_O = mse(D_Z_fake, torch.ones_like(D_O_fake))\n",
    "\n",
    "    cycle_orange = gen_O(fake_apple)\n",
    "    cycle_apple = gen_A(fake_orange)\n",
    "    cycle_orange_loss = L1(orange, cycle_orange)\n",
    "    cycle_apple_loss = L1(apple, cycle_apple)\n",
    "\n",
    "    identity_orange = gen_O(orange)\n",
    "    identity_apple = gen_A(apple)\n",
    "    identity_orange_loss = L1(orange, identity_orange)\n",
    "    identity_apple_loss = L1(apple, identity_apple)\n",
    "\n",
    "    G_loss = (loss_G_O + loss_G_A + cycle_orange_loss * lambda_cycle + cycle_apple_loss * lambda_cycle\n",
    "              +identity_apple_loss * lambda_identity + identity_orange_loss * lambda_identity)\n",
    "    G_loss.backward()\n",
    "    optim_gen.step()\n",
    "    if idx == 50:\n",
    "      print('EPOCH : ', epoch, 'G_loss : ', G_loss, 'D_loss :', D_loss)\n",
    "      break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gen_A, 'gen_H.pt')\n",
    "torch.save(gen_O, 'gen_Z.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_image = iter(dataloader).next()['A'][1]\n",
    "orange_image = iter(dataloader).next()['B'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_image = apple_image.to(device)\n",
    "orange_image = orange_image.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델에 이미지 넣어서 결과 확인.\n",
    "나름 잘 변환된 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(torchvision.utils.make_grid(apple_image.cpu(), normalize = True).permute(1, 2, 0)) \n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(torchvision.utils.make_grid(orange_image.cpu(), normalize = True).permute(1, 2, 0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_apple = gen_H(orange_image).cpu()\n",
    "plt.imshow(torchvision.utils.make_grid(trans_apple.cpu(), normalize = True).permute(1, 2, 0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_orange = gen_Z(apple_image).cpu()\n",
    "plt.imshow(torchvision.utils.make_grid(trans_orange.cpu(), normalize = True).permute(1, 2, 0)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "celeb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 24 2022, 14:07:00) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54b35b3adbbd70330d6102a494230c62f4578d0a77ac8239ed45d9ee8bea0e04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
